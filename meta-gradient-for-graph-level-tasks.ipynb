{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-05T13:20:34.905828Z",
     "iopub.status.busy": "2025-09-05T13:20:34.905497Z",
     "iopub.status.idle": "2025-09-05T13:20:35.173707Z",
     "shell.execute_reply": "2025-09-05T13:20:35.172902Z",
     "shell.execute_reply.started": "2025-09-05T13:20:34.905802Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pandas in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "!pip install pandas numpy \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T13:20:35.175101Z",
     "iopub.status.busy": "2025-09-05T13:20:35.174770Z",
     "iopub.status.idle": "2025-09-05T13:20:40.539853Z",
     "shell.execute_reply": "2025-09-05T13:20:40.538891Z",
     "shell.execute_reply.started": "2025-09-05T13:20:35.175082Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: torch_geometric in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch_geometric) (3.13.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch_geometric) (2025.9.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch_geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch_geometric) (2.0.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch_geometric) (7.0.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch_geometric) (3.2.4)\n",
      "Requirement already satisfied: requests in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch_geometric) (2.32.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch_geometric) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from aiohttp->torch_geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from aiohttp->torch_geometric) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from aiohttp->torch_geometric) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from aiohttp->torch_geometric) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from aiohttp->torch_geometric) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from aiohttp->torch_geometric) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from aiohttp->torch_geometric) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from aiohttp->torch_geometric) (1.22.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp->torch_geometric) (3.11)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from jinja2->torch_geometric) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from requests->torch_geometric) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from requests->torch_geometric) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from requests->torch_geometric) (2025.10.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from tqdm->torch_geometric) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T13:20:40.541311Z",
     "iopub.status.busy": "2025-09-05T13:20:40.541009Z",
     "iopub.status.idle": "2025-09-05T13:20:50.529249Z",
     "shell.execute_reply": "2025-09-05T13:20:50.528592Z",
     "shell.execute_reply.started": "2025-09-05T13:20:40.541284Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: torch in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "tensor([[0, 1, 0, 0, 1, 2],\n",
      "        [1, 2, 0, 0, 1, 2]])\n",
      "tensor([[0, 0, 1, 1, 2],\n",
      "        [0, 1, 1, 2, 2]])\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "from torch_geometric.datasets import Planetoid, Amazon, Reddit, WikiCS, Flickr, WebKB, Actor, PolBlogs, CitationFull\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.transforms import AddSelfLoops\n",
    "from torch_geometric.utils import subgraph, k_hop_subgraph\n",
    "import torch_geometric.transforms as T\n",
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch_geometric.nn import global_add_pool, global_max_pool, GlobalAttention, global_mean_pool\n",
    "from torch_geometric.nn.inits import glorot\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 0],\n",
    "                           [1, 2, 0]], dtype=torch.long)\n",
    "x = torch.tensor([[1,2,3],\n",
    "                 [4,5,6],\n",
    "                 [6,7,8]])\n",
    "y = torch.tensor([0,1,2])\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "# 创建 AddSelfLoops 转换\n",
    "add_self_loops = AddSelfLoops()\n",
    "# 应用转换\n",
    "data = add_self_loops(data)\n",
    "print(data.edge_index)\n",
    "data.edge_index = torch.unique(data.edge_index, dim=1)\n",
    "print(data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T13:20:50.531468Z",
     "iopub.status.busy": "2025-09-05T13:20:50.531052Z",
     "iopub.status.idle": "2025-09-05T13:20:50.662444Z",
     "shell.execute_reply": "2025-09-05T13:20:50.661579Z",
     "shell.execute_reply.started": "2025-09-05T13:20:50.531448Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\11326\\\\Desktop\\\\MetaPrompt'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T13:20:50.663825Z",
     "iopub.status.busy": "2025-09-05T13:20:50.663572Z",
     "iopub.status.idle": "2025-09-05T13:21:01.225417Z",
     "shell.execute_reply": "2025-09-05T13:21:01.224580Z",
     "shell.execute_reply.started": "2025-09-05T13:20:50.663803Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: scipy in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from scipy) (2.0.2)\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n",
      "17500\n",
      "18000\n",
      "18500\n",
      "19000\n",
      "19500\n",
      "Data(x=[30, 500], edge_index=[2, 100], y=1, index=0, node_idx=[30]) 0\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy\n",
    "def induced_graphs(data, device, smallest_size=10, largest_size=30):   # 构建诱导图的过程\n",
    "    induced_graph_list = []\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    for index in range(data.x.size(0)):\n",
    "        current_label = data.y[index].item()\n",
    "\n",
    "        current_hop = 2\n",
    "        subset, _, _, _ = k_hop_subgraph(node_idx=index, num_hops=current_hop,\n",
    "                                            edge_index=data.edge_index, relabel_nodes=True)\n",
    "        subset = subset\n",
    "\n",
    "        while len(subset) < smallest_size and current_hop < 5:\n",
    "            current_hop += 1\n",
    "            subset, _, _, _ = k_hop_subgraph(node_idx=index, num_hops=current_hop,\n",
    "                                                edge_index=data.edge_index)\n",
    "            \n",
    "        if len(subset) < smallest_size:\n",
    "            need_node_num = smallest_size - len(subset)\n",
    "            pos_nodes = torch.argwhere(data.y == int(current_label))   # Test data may leak\n",
    "            pos_nodes = pos_nodes.to('cpu')\n",
    "            subset = subset.to('cpu')\n",
    "            candidate_nodes = torch.from_numpy(np.setdiff1d(pos_nodes.numpy(), subset.numpy()))\n",
    "            candidate_nodes = candidate_nodes[torch.randperm(candidate_nodes.shape[0])][0:need_node_num]\n",
    "            subset = torch.cat([torch.flatten(subset), torch.flatten(candidate_nodes)])\n",
    "\n",
    "        if len(subset) > largest_size:\n",
    "            subset = subset[torch.randperm(subset.shape[0])][0:largest_size - 1]\n",
    "            subset = torch.unique(torch.cat([torch.LongTensor([index]).to(device), torch.flatten(subset).to(device)]))\n",
    "\n",
    "        subset = subset.to(device)\n",
    "        sub_edge_index, _ = subgraph(subset, data.edge_index, relabel_nodes=True)\n",
    "        sub_edge_index = sub_edge_index.to(device)\n",
    "\n",
    "        x = data.x[subset]\n",
    "\n",
    "        induced_graph = Data(x=x, edge_index=sub_edge_index, y=data.y[index], index=index, node_idx=subset.cpu())\n",
    "        add_self_loops = AddSelfLoops()\n",
    "        induced_graph = add_self_loops(induced_graph)\n",
    "        induced_graph.edge_index = torch.unique(induced_graph.edge_index, dim=1)\n",
    "        induced_graph_list.append(induced_graph)\n",
    "        if index%500 == 0:\n",
    "            print(index)\n",
    "    return induced_graph_list\n",
    "\n",
    "\n",
    "transform_list = [T.AddSelfLoops(), T.ToUndirected(), T.NormalizeFeatures()]\n",
    "transform = T.Compose(transform_list)\n",
    "dataset = Planetoid(root='c:/Users/11326/Desktop/MetaPrompt', name='PubMed', transform=transform)\n",
    "data = dataset[0]\n",
    "graph_list = induced_graphs(data, 'cpu')\n",
    "print(graph_list[0],graph_list[0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T13:21:01.226791Z",
     "iopub.status.busy": "2025-09-05T13:21:01.226225Z",
     "iopub.status.idle": "2025-09-05T13:21:01.383748Z",
     "shell.execute_reply": "2025-09-05T13:21:01.383108Z",
     "shell.execute_reply.started": "2025-09-05T13:21:01.226758Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[30, 500], edge_index=[2, 100], y=1, index=0, node_idx=[30], adj=[30, 30])\n"
     ]
    }
   ],
   "source": [
    "def normalize_adj_tensor(adj):\n",
    "    # gcn的归一化邻接矩阵方法\n",
    "    D = torch.sum(adj, dim=1)\n",
    "    D_inv = torch.pow(D, -1 / 2)\n",
    "    D_inv[torch.isinf(D_inv)] = 0.\n",
    "    D_mat_inv = torch.diag(D_inv)\n",
    "    adj_norm = D_mat_inv @ adj @ D_mat_inv  # GCN的归一化方式\n",
    "    return adj_norm\n",
    "\n",
    "def edge_index_to_adjacency_matrix(edge_index, num_nodes, undirected=True, device='cpu'):  \n",
    "    # 将edge_indedx转化为邻接矩阵\n",
    "    # 构建一个大小为 (num_nodes, num_nodes) 的零矩阵  \n",
    "    adjacency_matrix = torch.zeros(num_nodes, num_nodes, dtype=torch.uint8).to(device)\n",
    "      \n",
    "    # 使用索引广播机制，一次性将边索引映射到邻接矩阵的相应位置上  \n",
    "    if undirected:\n",
    "        adjacency_matrix[edge_index[0], edge_index[1]] = 1  \n",
    "        adjacency_matrix[edge_index[1], edge_index[0]] = 1  \n",
    "    else:\n",
    "        adjacency_matrix[edge_index[0], edge_index[1]] = 1\n",
    "    return adjacency_matrix\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "size_buffer = []\n",
    "for graph in graph_list:\n",
    "    size_buffer.append(graph.x.shape[0])\n",
    "    adj = edge_index_to_adjacency_matrix(graph.edge_index, graph.x.shape[0])\n",
    "    graph.adj = adj\n",
    "\n",
    "print(graph_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T13:21:01.384837Z",
     "iopub.status.busy": "2025-09-05T13:21:01.384534Z",
     "iopub.status.idle": "2025-09-05T13:21:01.394604Z",
     "shell.execute_reply": "2025-09-05T13:21:01.393841Z",
     "shell.execute_reply.started": "2025-09-05T13:21:01.384809Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, graph_list):\n",
    "        self.graph_list = graph_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graph_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graph_list[idx]\n",
    "\n",
    "class SequentialGraphLoader(DataLoader):\n",
    "    def __init__(self, graph_list, batch_size=1):\n",
    "        dataset = GraphDataset(graph_list)\n",
    "        super(SequentialGraphLoader, self).__init__(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.dataset), self.batch_size):\n",
    "            batch = self.dataset[i:i+self.batch_size]\n",
    "            yield self.merge_graphs(batch)\n",
    "\n",
    "    def merge_graphs(self, batch):\n",
    "        # 合并子图的特征矩阵和邻接矩阵\n",
    "        x_buffer = []\n",
    "        adj_list = []\n",
    "        y_buffer = []\n",
    "        batch_sizes = []\n",
    "        batch_indexs = []\n",
    "        graph_indexs = []\n",
    "\n",
    "        for i, graph in enumerate(batch):\n",
    "            x = graph.x\n",
    "            adj = graph.adj\n",
    "            y = graph.y.unsqueeze(0)  # 确保 y 是二维张量\n",
    "            x_buffer.append(x)\n",
    "            adj_list.append(adj)\n",
    "            y_buffer.append(y)\n",
    "            batch_sizes.append(x.shape[0])  # 存储子图的大小\n",
    "            batch_indexs = batch_indexs + [i] * x.shape[0]\n",
    "            graph_indexs.append(graph.index)\n",
    "\n",
    "        # 将特征矩阵堆叠\n",
    "        x_combined = torch.cat(x_buffer, dim=0)  # 合并特征矩阵\n",
    "        num_nodes = x_combined.size(0)  # 所有节点的总数\n",
    "        \n",
    "        # 构建大的邻接矩阵\n",
    "        adj_combined = torch.zeros(num_nodes, num_nodes, device=x_combined.device)\n",
    "        start = 0\n",
    "        for i in range(len(batch)):\n",
    "            end = start + batch_sizes[i]\n",
    "            adj_combined[start:end, start:end] = adj_list[i]  # 填充对应的子图邻接矩阵\n",
    "            start = end\n",
    "\n",
    "        y_combined = torch.cat(y_buffer, dim=0)  # 合并标签\n",
    "        batch_indexs = torch.tensor(batch_indexs)\n",
    "\n",
    "        return x_combined, adj_combined, y_combined, batch_sizes, batch_indexs, graph_indexs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T13:21:01.396107Z",
     "iopub.status.busy": "2025-09-05T13:21:01.395431Z",
     "iopub.status.idle": "2025-09-05T13:21:06.522402Z",
     "shell.execute_reply": "2025-09-05T13:21:06.521691Z",
     "shell.execute_reply.started": "2025-09-05T13:21:01.396078Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_num: 0\n",
      "epoch_num: 1\n",
      "epoch_num: 2\n",
      "epoch_num: 3\n",
      "epoch_num: 4\n",
      "epoch_num: 5\n",
      "epoch_num: 6\n",
      "epoch_num: 7\n",
      "epoch_num: 8\n",
      "epoch_num: 9\n",
      "done\n",
      "tensor([[ 0.0000e+00, -8.3030e-03, -9.4024e-02,  1.3133e-02,  5.3624e-03,\n",
      "         -5.4614e-02, -5.0017e-02, -9.5712e-02,  3.3067e-02,  1.1298e-02,\n",
      "         -4.1460e-02,  7.0353e-03, -1.5893e-02,  6.0334e-02, -4.5451e-02,\n",
      "         -7.5644e-02, -3.0409e-02,  3.2771e-02, -9.8506e-02, -1.0217e-01,\n",
      "          1.6811e-02,  3.6578e-02, -2.9776e-02, -1.1194e-02, -5.2711e-02,\n",
      "         -6.3101e-02, -3.8200e-02, -5.0844e-02, -2.6315e-01,  1.8205e-02],\n",
      "        [ 1.4050e-02,  0.0000e+00, -1.4871e-01,  4.1130e-03, -8.1551e-03,\n",
      "         -9.0748e-02, -8.3994e-02, -1.5120e-01,  3.8749e-02,  1.4864e-03,\n",
      "         -7.2982e-02, -1.8706e-04, -3.3809e-02,  7.8428e-02, -7.5691e-02,\n",
      "         -1.2168e-01, -5.5149e-02,  3.7762e-02, -1.5688e-01, -1.6079e-01,\n",
      "          1.4930e-02,  4.2627e-02, -5.9641e-02, -2.6890e-02, -8.8055e-02,\n",
      "         -1.0481e-01, -6.6607e-02, -8.5210e-02, -4.0727e-01,  1.6340e-02],\n",
      "        [ 1.0737e-01,  7.0883e-02,  0.0000e+00,  9.7002e-02,  8.4735e-02,\n",
      "          3.2260e-03,  9.9343e-03, -5.6821e-02,  1.3191e-01,  9.4399e-02,\n",
      "          2.0723e-02,  9.3174e-02,  5.9786e-02,  1.7129e-01,  1.8333e-02,\n",
      "         -2.7504e-02,  3.8588e-02,  1.3088e-01, -6.2616e-02, -6.6364e-02,\n",
      "          1.0826e-01,  1.3564e-01,  3.3609e-02,  6.6659e-02,  5.8913e-03,\n",
      "         -1.0893e-02,  2.7206e-02,  8.7261e-03, -3.1213e-01,  1.0960e-01],\n",
      "        [ 2.2757e-02, -4.6071e-03, -1.0770e-01,  0.0000e+00,  4.0176e-02,\n",
      "         -6.0323e-02, -5.4757e-02, -1.0973e-01,  4.2411e-02,  4.2708e-02,\n",
      "         -3.6520e-02,  1.4384e-02, -1.3703e-02,  7.7352e-02, -5.7276e-02,\n",
      "         -8.5588e-02, -3.1202e-02,  4.4844e-02, -1.0515e-01, -1.1700e-01,\n",
      "          2.2408e-02,  5.3125e-02, -3.0674e-03, -8.0855e-03, -5.7495e-02,\n",
      "         -6.2556e-02, -4.0575e-02, -5.5752e-02, -2.6157e-01,  2.7320e-02],\n",
      "        [ 3.7833e-02,  9.9324e-03, -9.5827e-02,  6.2933e-02,  0.0000e+00,\n",
      "         -4.7226e-02, -4.1513e-02, -9.7911e-02,  5.7960e-02,  6.0261e-02,\n",
      "         -2.2206e-02,  2.9455e-02,  6.0351e-04,  9.3966e-02, -4.4701e-02,\n",
      "         -7.3142e-02, -1.7351e-02,  6.0667e-02, -9.2614e-02, -1.0533e-01,\n",
      "          3.7406e-02,  6.9441e-02,  1.3576e-02,  6.3640e-03, -4.4285e-02,\n",
      "         -4.8916e-02, -2.6967e-02, -4.2534e-02, -2.4994e-01,  4.2689e-02],\n",
      "        [ 6.2034e-02,  2.5346e-02, -1.0073e-01,  5.2097e-02,  3.9829e-02,\n",
      "          0.0000e+00, -3.6010e-02, -1.0321e-01,  8.6733e-02,  4.9470e-02,\n",
      "         -2.4998e-02,  4.7797e-02,  1.4175e-02,  1.2641e-01, -2.7707e-02,\n",
      "         -7.3699e-02, -7.1650e-03,  8.5746e-02, -1.0890e-01, -1.1281e-01,\n",
      "          6.2914e-02,  9.0611e-02, -1.1657e-02,  2.1093e-02, -4.0071e-02,\n",
      "         -5.6826e-02, -1.8623e-02, -3.7226e-02, -3.5929e-01,  6.4324e-02],\n",
      "        [ 6.1647e-02,  2.5159e-02, -1.0008e-01,  5.1278e-02,  3.9011e-02,\n",
      "         -4.2498e-02,  0.0000e+00, -1.0255e-01,  8.6190e-02,  4.8676e-02,\n",
      "         -2.5000e-02,  4.7451e-02,  1.4063e-02,  1.2557e-01, -2.7390e-02,\n",
      "         -7.3228e-02, -7.1352e-03,  8.5157e-02, -1.0834e-01, -1.1209e-01,\n",
      "          6.2538e-02,  8.9920e-02, -1.2114e-02,  2.0935e-02, -3.9832e-02,\n",
      "         -5.6616e-02, -1.8517e-02, -3.6997e-02, -3.5785e-01,  6.3878e-02],\n",
      "        [ 1.0912e-01,  7.2636e-02, -5.2602e-02,  9.8755e-02,  8.6489e-02,\n",
      "          4.9797e-03,  1.1688e-02,  0.0000e+00,  1.3367e-01,  9.6153e-02,\n",
      "          2.2477e-02,  9.4928e-02,  6.1540e-02,  1.7304e-01,  2.0087e-02,\n",
      "         -2.5750e-02,  4.0342e-02,  1.3263e-01, -6.0862e-02, -6.4610e-02,\n",
      "          1.1002e-01,  1.3740e-01,  3.5363e-02,  6.8413e-02,  7.6451e-03,\n",
      "         -9.1387e-03,  2.8960e-02,  1.0480e-02, -3.1037e-01,  1.1135e-01],\n",
      "        [-3.9890e-03, -2.9701e-02, -1.1789e-01, -1.1511e-02, -2.0184e-02,\n",
      "         -7.7342e-02, -7.2619e-02, -1.1963e-01,  0.0000e+00, -1.3340e-02,\n",
      "         -6.5088e-02, -1.4009e-02, -3.7515e-02,  4.1006e-02, -6.6637e-02,\n",
      "         -9.8981e-02, -5.2441e-02,  1.2547e-02, -1.2377e-01, -1.2635e-01,\n",
      "         -3.3535e-03,  1.5870e-02, -5.6176e-02, -3.2675e-02, -7.5470e-02,\n",
      "         -8.7350e-02, -6.0456e-02, -7.3469e-02, -2.9982e-01, -2.4375e-03],\n",
      "        [ 2.1954e-02, -5.1488e-03, -1.0611e-01,  4.0465e-02,  3.4892e-02,\n",
      "         -5.9709e-02, -5.4263e-02, -1.0810e-01,  4.1264e-02,  0.0000e+00,\n",
      "         -3.7473e-02,  1.3376e-02, -1.4061e-02,  7.5192e-02, -5.5652e-02,\n",
      "         -8.4454e-02, -3.1192e-02,  4.3272e-02, -1.0468e-01, -1.1528e-01,\n",
      "          2.1736e-02,  5.0882e-02, -7.3232e-03, -8.5550e-03, -5.7012e-02,\n",
      "         -6.2969e-02, -4.0370e-02, -5.5237e-02, -2.6346e-01,  2.6111e-02],\n",
      "        [ 7.4207e-02,  3.4705e-02, -1.0310e-01,  7.0310e-02,  5.8019e-02,\n",
      "         -3.9746e-02, -3.2354e-02, -1.0581e-01,  1.0108e-01,  6.7341e-02,\n",
      "          0.0000e+00,  5.9388e-02,  2.2504e-02,  1.4502e-01, -2.5393e-02,\n",
      "         -7.3552e-02, -8.3272e-04,  1.0074e-01, -1.0993e-01, -1.1617e-01,\n",
      "          7.4926e-02,  1.0703e-01,  1.4834e-03,  3.0057e-02, -3.6660e-02,\n",
      "         -5.3011e-02, -1.3358e-02, -3.3683e-02, -3.7263e-01,  7.7321e-02],\n",
      "        [-2.4742e-03, -3.9652e-02, -1.6777e-01, -1.1362e-02, -2.3634e-02,\n",
      "         -1.0886e-01, -1.0200e-01, -1.7029e-01,  2.2602e-02, -1.4048e-02,\n",
      "         -9.0444e-02,  0.0000e+00, -5.1001e-02,  6.3022e-02, -9.3929e-02,\n",
      "         -1.4030e-01, -7.2688e-02,  2.1727e-02, -1.7570e-01, -1.8002e-01,\n",
      "         -1.6220e-03,  2.6841e-02, -7.5998e-02, -4.3973e-02, -1.0610e-01,\n",
      "         -1.2279e-01, -8.4332e-02, -1.0323e-01, -4.2823e-01, -4.1173e-05],\n",
      "        [ 2.6192e-02, -1.0296e-02, -1.3553e-01,  1.5823e-02,  3.5565e-03,\n",
      "         -7.7953e-02, -7.1244e-02, -1.3800e-01,  5.0735e-02,  1.3221e-02,\n",
      "         -6.0455e-02,  1.1996e-02,  0.0000e+00,  9.0110e-02, -6.2845e-02,\n",
      "         -1.0868e-01, -4.2590e-02,  4.9702e-02, -1.4379e-01, -1.4754e-01,\n",
      "          2.7083e-02,  5.4465e-02, -4.7569e-02, -1.4520e-02, -7.5287e-02,\n",
      "         -9.2071e-02, -5.3972e-02, -7.2452e-02, -3.9331e-01,  2.8423e-02],\n",
      "        [-1.1505e-01, -1.7744e-01, -3.9952e-01, -1.0656e-01, -1.2400e-01,\n",
      "         -2.9743e-01, -2.8550e-01, -4.0389e-01, -7.2008e-02, -1.1155e-01,\n",
      "         -2.5827e-01, -1.3736e-01, -1.9709e-01,  0.0000e+00, -2.7877e-01,\n",
      "         -3.5189e-01, -2.3472e-01, -7.0998e-02, -4.0608e-01, -4.2030e-01,\n",
      "         -1.1441e-01, -5.8780e-02, -2.1566e-01, -1.8493e-01, -2.9216e-01,\n",
      "         -3.1434e-01, -2.5490e-01, -2.8764e-01, -8.0614e-01, -1.0874e-01],\n",
      "        [ 4.8982e-02,  1.9467e-02, -8.1632e-02,  3.9920e-02,  2.9907e-02,\n",
      "         -3.5149e-02, -2.9734e-02, -8.3623e-02,  6.8807e-02,  3.7829e-02,\n",
      "         -2.1233e-02,  3.7448e-02,  1.0509e-02,  1.0054e-01,  0.0000e+00,\n",
      "         -5.9957e-02, -6.6024e-03,  6.7900e-02, -8.8509e-02, -9.1339e-02,\n",
      "          4.9726e-02,  7.1648e-02, -1.1339e-02,  1.6058e-02, -3.3011e-02,\n",
      "         -4.6755e-02, -1.5791e-02, -3.0710e-02, -2.9102e-01,  5.0722e-02],\n",
      "        [ 8.8273e-02,  5.1786e-02, -7.3453e-02,  7.7905e-02,  6.5638e-02,\n",
      "         -1.5871e-02, -9.1627e-03, -7.5919e-02,  1.1282e-01,  7.5302e-02,\n",
      "          1.6262e-03,  7.4077e-02,  4.0689e-02,  1.5219e-01, -7.6385e-04,\n",
      "          0.0000e+00,  1.9491e-02,  1.1178e-01, -8.1713e-02, -8.5461e-02,\n",
      "          8.9165e-02,  1.1655e-01,  1.4512e-02,  4.7562e-02, -1.3206e-02,\n",
      "         -2.9990e-02,  8.1093e-03, -1.0371e-02, -3.3122e-01,  9.0504e-02],\n",
      "        [ 3.6954e-02,  2.6566e-04, -1.2581e-01,  2.7017e-02,  1.4749e-02,\n",
      "         -6.7844e-02, -6.1090e-02, -1.2829e-01,  6.1653e-02,  2.4390e-02,\n",
      "         -5.0078e-02,  2.2717e-02, -1.0905e-02,  1.0133e-01, -5.2787e-02,\n",
      "         -9.8779e-02,  0.0000e+00,  6.0666e-02, -1.3398e-01, -1.3789e-01,\n",
      "          3.7834e-02,  6.5531e-02, -3.6737e-02, -3.9865e-03, -6.5151e-02,\n",
      "         -8.1906e-02, -4.3703e-02, -6.2306e-02, -3.8437e-01,  3.9244e-02],\n",
      "        [-2.4371e-02, -6.0859e-02, -1.8610e-01, -3.4740e-02, -4.7007e-02,\n",
      "         -1.2852e-01, -1.2181e-01, -1.8856e-01,  1.7184e-04, -3.7342e-02,\n",
      "         -1.1102e-01, -3.8567e-02, -7.1956e-02,  3.9547e-02, -1.1341e-01,\n",
      "         -1.5925e-01, -9.3153e-02,  0.0000e+00, -1.9436e-01, -1.9811e-01,\n",
      "         -2.3480e-02,  3.9022e-03, -9.8132e-02, -6.5083e-02, -1.2585e-01,\n",
      "         -1.4263e-01, -1.0454e-01, -1.2302e-01, -4.4387e-01, -2.2140e-02],\n",
      "        [ 1.4043e-01,  1.0092e-01, -3.6879e-02,  1.3653e-01,  1.2424e-01,\n",
      "          2.6474e-02,  3.3866e-02, -3.9593e-02,  1.6730e-01,  1.3356e-01,\n",
      "          4.8000e-02,  1.2561e-01,  8.8724e-02,  2.1124e-01,  4.0827e-02,\n",
      "         -7.3316e-03,  6.5387e-02,  1.6696e-01,  0.0000e+00, -4.9951e-02,\n",
      "          1.4115e-01,  1.7325e-01,  6.7704e-02,  9.6277e-02,  2.9560e-02,\n",
      "          1.3209e-02,  5.2862e-02,  3.2537e-02, -3.0641e-01,  1.4354e-01],\n",
      "        [ 1.1129e-01,  7.4115e-02, -5.4000e-02,  1.0240e-01,  9.0132e-02,\n",
      "          4.9029e-03,  1.1768e-02, -5.6522e-02,  1.3637e-01,  9.9719e-02,\n",
      "          2.3322e-02,  9.6954e-02,  6.2765e-02,  1.7679e-01,  1.9837e-02,\n",
      "         -2.6531e-02,  4.1078e-02,  1.3549e-01, -6.1932e-02,  0.0000e+00,\n",
      "          1.1214e-01,  1.4061e-01,  3.7769e-02,  6.9794e-02,  7.6645e-03,\n",
      "         -9.0202e-03,  2.9434e-02,  1.0532e-02, -3.1446e-01,  1.1373e-01],\n",
      "        [-2.6632e-03, -3.0351e-02, -1.2677e-01, -5.9441e-03, -1.4633e-02,\n",
      "         -8.2445e-02, -7.7273e-02, -1.2867e-01,  1.6150e-02, -8.0133e-03,\n",
      "         -6.7550e-02, -1.3091e-02, -3.8889e-02,  4.6848e-02, -7.2235e-02,\n",
      "         -1.0610e-01, -5.5217e-02,  1.5852e-02, -1.3172e-01, -1.3593e-01,\n",
      "          0.0000e+00,  2.0179e-02, -5.4171e-02, -3.3603e-02, -8.0297e-02,\n",
      "         -9.1894e-02, -6.3981e-02, -7.8203e-02, -3.1641e-01, -5.3280e-04],\n",
      "        [-1.5726e-02, -4.3414e-02, -1.3984e-01, -1.9007e-02, -2.7696e-02,\n",
      "         -9.5508e-02, -9.0336e-02, -1.4174e-01,  3.0870e-03, -2.1076e-02,\n",
      "         -8.0613e-02, -2.6154e-02, -5.1952e-02,  3.3785e-02, -8.5297e-02,\n",
      "         -1.1916e-01, -6.8280e-02,  2.7889e-03, -1.4478e-01, -1.4899e-01,\n",
      "         -1.5203e-02,  0.0000e+00, -6.7234e-02, -4.6666e-02, -9.3359e-02,\n",
      "         -1.0496e-01, -7.7043e-02, -9.1266e-02, -3.2947e-01, -1.3596e-02],\n",
      "        [ 7.4253e-02,  4.0816e-02, -8.1570e-02,  8.9931e-02,  8.2089e-02,\n",
      "         -2.5319e-02, -1.8726e-02, -8.3980e-02,  9.7780e-02,  8.7026e-02,\n",
      "         -4.0967e-04,  6.3132e-02,  3.0004e-02,  1.3836e-01, -1.8357e-02,\n",
      "         -5.5323e-02,  9.2482e-03,  9.9499e-02, -8.1874e-02, -9.2817e-02,\n",
      "          7.4224e-02,  1.0778e-01,  0.0000e+00,  3.6687e-02, -2.2187e-02,\n",
      "         -3.1314e-02, -1.8778e-03, -1.9907e-02, -2.8501e-01,  7.8699e-02],\n",
      "        [ 1.7046e-02, -1.9643e-02, -1.4572e-01,  7.1086e-03, -5.1595e-03,\n",
      "         -8.7752e-02, -8.0998e-02, -1.4820e-01,  4.1744e-02,  4.4821e-03,\n",
      "         -6.9987e-02,  2.8086e-03, -3.0813e-02,  8.1424e-02, -7.2695e-02,\n",
      "         -1.1869e-01, -5.2153e-02,  4.0758e-02, -1.5388e-01, -1.5780e-01,\n",
      "          1.7926e-02,  4.5623e-02, -5.6646e-02,  0.0000e+00, -8.5059e-02,\n",
      "         -1.0181e-01, -6.3611e-02, -8.2215e-02, -4.0428e-01,  1.9336e-02],\n",
      "        [ 5.9767e-02,  2.2590e-02, -1.0552e-01,  5.0880e-02,  3.8607e-02,\n",
      "         -4.6622e-02, -3.9757e-02, -1.0805e-01,  8.4844e-02,  4.8194e-02,\n",
      "         -2.8203e-02,  4.5429e-02,  1.1240e-02,  1.2526e-01, -3.1688e-02,\n",
      "         -7.8056e-02, -1.0447e-02,  8.3969e-02, -1.1346e-01, -1.1778e-01,\n",
      "          6.0619e-02,  8.9083e-02, -1.3756e-02,  1.8269e-02,  0.0000e+00,\n",
      "         -6.0545e-02, -2.2091e-02, -4.0993e-02, -3.6599e-01,  6.2200e-02],\n",
      "        [ 9.9329e-02,  5.9826e-02, -7.7978e-02,  9.5431e-02,  8.3140e-02,\n",
      "         -1.4625e-02, -7.2325e-03, -8.0692e-02,  1.2620e-01,  9.2463e-02,\n",
      "          6.9011e-03,  8.4509e-02,  4.7625e-02,  1.7014e-01, -2.7199e-04,\n",
      "         -4.8430e-02,  2.4289e-02,  1.2586e-01, -8.4807e-02, -9.1049e-02,\n",
      "          1.0005e-01,  1.3215e-01,  2.6605e-02,  5.5178e-02, -1.1539e-02,\n",
      "          0.0000e+00,  1.1764e-02, -8.5620e-03, -3.4751e-01,  1.0244e-01],\n",
      "        [ 4.5027e-02,  8.3381e-03, -1.1774e-01,  3.5089e-02,  2.2821e-02,\n",
      "         -5.9772e-02, -5.3018e-02, -1.2022e-01,  6.9725e-02,  3.2463e-02,\n",
      "         -4.2006e-02,  3.0789e-02, -2.8321e-03,  1.0940e-01, -4.4715e-02,\n",
      "         -9.0707e-02, -2.4172e-02,  6.8738e-02, -1.2590e-01, -1.2982e-01,\n",
      "          4.5907e-02,  7.3604e-02, -2.8665e-02,  4.0860e-03, -5.7078e-02,\n",
      "         -7.3833e-02,  0.0000e+00, -5.4234e-02, -3.7629e-01,  4.7317e-02],\n",
      "        [ 6.2506e-02,  2.6018e-02, -9.9220e-02,  5.2137e-02,  3.9871e-02,\n",
      "         -4.1638e-02, -3.4930e-02, -1.0169e-01,  8.7049e-02,  4.9535e-02,\n",
      "         -2.4141e-02,  4.8310e-02,  1.4922e-02,  1.2642e-01, -2.6531e-02,\n",
      "         -7.2368e-02, -6.2759e-03,  8.6016e-02, -1.0748e-01, -1.1123e-01,\n",
      "          6.3398e-02,  9.0779e-02, -1.1255e-02,  2.1795e-02, -3.8973e-02,\n",
      "         -5.5757e-02, -1.7658e-02,  0.0000e+00, -3.5699e-01,  6.4737e-02],\n",
      "        [ 6.9109e-01,  6.2870e-01,  4.0662e-01,  6.9958e-01,  6.8214e-01,\n",
      "          5.0871e-01,  5.2064e-01,  4.0225e-01,  7.3413e-01,  6.9459e-01,\n",
      "          5.4787e-01,  6.6878e-01,  6.0906e-01,  8.0614e-01,  5.2737e-01,\n",
      "          4.5425e-01,  5.7142e-01,  7.3514e-01,  4.0007e-01,  3.8584e-01,\n",
      "          6.9173e-01,  7.4736e-01,  5.9048e-01,  6.2121e-01,  5.1398e-01,\n",
      "          4.9180e-01,  5.5124e-01,  5.1850e-01,  0.0000e+00,  6.9740e-01],\n",
      "        [-9.2371e-03, -4.5725e-02, -1.7096e-01, -1.9606e-02, -3.1872e-02,\n",
      "         -1.1338e-01, -1.0667e-01, -1.7343e-01,  1.5306e-02, -2.2208e-02,\n",
      "         -9.5884e-02, -2.3433e-02, -5.6821e-02,  5.4681e-02, -9.8274e-02,\n",
      "         -1.4411e-01, -7.8019e-02,  1.4273e-02, -1.7922e-01, -1.8297e-01,\n",
      "         -8.3456e-03,  1.9036e-02, -8.2998e-02, -4.9949e-02, -1.1072e-01,\n",
      "         -1.2750e-01, -8.9401e-02, -1.0788e-01, -4.2874e-01,  0.0000e+00]])\n",
      "Saved modified_full_graph.npz\n",
      "Saved pubmed_mod_adj_005.npz (sparse matrix format)\n",
      "Saved pubmed_mod_adj_005.npz (sparse matrix format)\n",
      "验证成功: pubmed_mod_adj_005.npz - 形状: (19717, 19717), 类型: <class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Batch, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import math\n",
    "import copy\n",
    "\n",
    "modified_graph_list = copy.deepcopy(graph_list)\n",
    "adj_changes = [torch.nn.Parameter(torch.FloatTensor(size, size)) for size in size_buffer] # 对每个子图的扰动\n",
    "for adj_change in adj_changes:\n",
    "    adj_change.data.fill_(0)\n",
    "for modified_graph, graph, adj_change in zip(modified_graph_list, graph_list, adj_changes):\n",
    "    change_square = adj_change - torch.diag(torch.diag(adj_change, 0))\n",
    "    change_square = torch.clamp(change_square, -1, 1)\n",
    "    modified_graph.adj = change_square + graph.adj\n",
    "\n",
    "train_loader = SequentialGraphLoader(modified_graph_list[:800], batch_size=16) # 定义的Dataloader\n",
    "test_loader = SequentialGraphLoader(modified_graph_list[800:], batch_size=16)\n",
    "weights = []\n",
    "w_velocities = []\n",
    "hidden_sizes = [128 for i in range(2)]\n",
    "previous_size = 500\n",
    "out_dim = 7\n",
    "for ix, nhid in enumerate(hidden_sizes):\n",
    "    weight = torch.nn.Parameter(torch.FloatTensor(previous_size, nhid).to(device))\n",
    "    w_velocity = torch.zeros(weight.shape).to(device)\n",
    "    weights.append(weight)\n",
    "    w_velocities.append(w_velocity)\n",
    "    previous_size = nhid\n",
    "    \n",
    "output_weight = torch.nn.Parameter(torch.FloatTensor(previous_size, out_dim).to(device))\n",
    "output_w_velocity = torch.zeros(output_weight.shape).to(device)\n",
    "weights.append(output_weight)\n",
    "w_velocities.append(output_w_velocity)\n",
    "for w, v in zip(weights, w_velocities):\n",
    "    stdv = 1. / math.sqrt(w.size(1))\n",
    "    w.data.uniform_(-stdv, stdv)\n",
    "    v.data.fill_(0)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # 分类任务的损失函数\n",
    "\n",
    "\n",
    "#初始化参数,避免梯度爆炸\n",
    "for w, v in zip(weights, w_velocities):\n",
    "    stdv = 1. / math.sqrt(w.size(1))\n",
    "    w.data.uniform_(-stdv, stdv)\n",
    "    v.data.fill_(0)\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(\"epoch_num:\", epoch)\n",
    "    for x, adj, y, sizes, batch_indexs, graph_indexs in train_loader:\n",
    "        loss = 0.0\n",
    "        x, adj, y, batch_indexs = x.to(device), adj.to(device), y.to(device), batch_indexs.to(device)\n",
    "        adj_norm = normalize_adj_tensor(adj)\n",
    "        \n",
    "        # 图卷积\n",
    "        for i, w in enumerate(weights):\n",
    "            if i != len(weights)-1:\n",
    "                x = adj_norm @ x @ w\n",
    "            else:\n",
    "                x = global_mean_pool(x, batch_indexs) @ w\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = criterion(x, y)\n",
    "        assert torch.isnan(loss).any()==False, \"loss is NaN\"\n",
    "        if torch.isnan(loss).any():\n",
    "            raise ValueError(\"loss is NaN!\")\n",
    "        weight_grads = torch.autograd.grad(loss, weights, create_graph=True)\n",
    "        w_velocities = [0.9 * v + g for v, g in zip(w_velocities, weight_grads)]\n",
    "        weights = [w - 0.01 * v for w, v in zip(weights, w_velocities)]\n",
    "        \n",
    "total_loss = 0.0\n",
    "for x, adj, y, sizes, batch_indexs, graph_indexs in test_loader:\n",
    "    x, adj, y, batch_indexs = x.to(device), adj.to(device), y.to(device), batch_indexs.to(device)\n",
    "    adj_norm = normalize_adj_tensor(adj)\n",
    "    \n",
    "    # 图卷积\n",
    "    for i, w in enumerate(weights):\n",
    "        if i != len(weights)-1:\n",
    "            x = adj_norm @ x @ w\n",
    "        else:\n",
    "            x = global_mean_pool(x, batch_indexs) @ w\n",
    "        \n",
    "    # 累计损失\n",
    "    total_loss += criterion(x, y) * x.shape[0]\n",
    "\n",
    "total_loss.backward(retain_graph=False)\n",
    "\n",
    "# 提取元梯度\n",
    "adj_grads = [adj_change.grad for adj_change in adj_changes]\n",
    "\n",
    "# 验证形状\n",
    "for grad, adj_change in zip(adj_grads, adj_changes):\n",
    "    assert grad.shape == adj_change.shape\n",
    "print(\"done\")\n",
    "print(adj_grads[0])\n",
    "# -------------------------\n",
    "# 在 total_loss.backward(...) 和 adj_grads 之后运行\n",
    "# -------------------------\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# attack_ratio: 你在 adj_changes 定义处设定，比如 0.05 表示每个子图翻 / 注入 5% 的“可能边位”\n",
    "# 若你还没定义，请在这里设置（或改为从上面单元读取）\n",
    "attack_ratio = 0.25\n",
    "\n",
    "# adj_grads 已经存在（list of tensors，shape 与对应 adj_change 相同）\n",
    "# graph_list 与 modified_graph_list 在前面单元已定义\n",
    "adj_grads = [g.detach().cpu().numpy() for g in adj_grads]  # 转 numpy 便于处理\n",
    "\n",
    "def apply_budgeted_flips_to_subgraph(orig_adj, grad_mat, ratio):\n",
    "    \"\"\"\n",
    "    orig_adj: torch tensor 或 numpy 二值邻接 (n_i, n_i)\n",
    "    grad_mat: numpy ndarray, 对应 adj_change.grad 的绝对值敏感度矩阵 (n_i, n_i)\n",
    "    ratio: 比例 (0~1)，表示要翻转的边/位置占上三角（不含对角）的比例\n",
    "    返回: 修改后的二值邻接 numpy (n_i, n_i)\n",
    "    \"\"\"\n",
    "    if isinstance(orig_adj, torch.Tensor):\n",
    "        A = orig_adj.detach().cpu().numpy().astype(np.int8)\n",
    "    else:\n",
    "        A = np.array(orig_adj, dtype=np.int8)\n",
    "    n = A.shape[0]\n",
    "    # 只考虑上三角（i<j）的候选位置（无向图）\n",
    "    iu = np.triu_indices(n, k=1)\n",
    "    # score = abs(grad)\n",
    "    scores = np.abs(grad_mat[iu])\n",
    "    m = len(scores)\n",
    "    k = max(1, int(np.round(ratio * m)))  # 至少选 1 个\n",
    "    if k >= m:\n",
    "        top_idx = np.arange(m)\n",
    "    else:\n",
    "        top_idx = np.argpartition(-scores, k-1)[:k]  # top-k indices within iu\n",
    "    rows = iu[0][top_idx]\n",
    "    cols = iu[1][top_idx]\n",
    "    # flip edges at (rows, cols)\n",
    "    A_new = A.copy()\n",
    "    A_new[rows, cols] = 1 - A_new[rows, cols]  # flip: 1->0, 0->1\n",
    "    A_new[cols, rows] = A_new[rows, cols]      # 对称\n",
    "    # 保持对角为0\n",
    "    np.fill_diagonal(A_new, 0)\n",
    "    return A_new\n",
    "\n",
    "# 遍历每个子图，按比例把梯度大的位置翻转成最终的二值邻接\n",
    "for i, (sg, grad) in enumerate(zip(modified_graph_list, adj_grads)):\n",
    "    # sg.adj 可能是 torch.Tensor；把 grad 传进去\n",
    "    new_adj = apply_budgeted_flips_to_subgraph(sg.adj, grad, attack_ratio)\n",
    "    # 把 numpy 转回 torch（或保持 numpy，后面拼接时统一处理）\n",
    "    sg.adj = torch.from_numpy(new_adj).to(sg.x.device)\n",
    "\n",
    "# 至此 modified_graph_list 已经包含“最终二值化后的子图邻接”\n",
    "# 下一步：把子图拼回为一张大图并保存为 npz\n",
    "# 需要每个 subgraph 包含原图 node id 映射：graph.index（你的 induced_graph 保存了 index 字段）\n",
    "# 如果每个 subgraph 里有 attribute 'index' 为中心节点 id，可以用它和子图节点顺序做映射（若你在构造子图时保留了 node_idx 那更好）\n",
    "\n",
    "# 这里基于你的 induced_graphs 函数：每个 subgraph 的 .index = 中心节点（单个node）\n",
    "# 如果想要正确拼回原大图（non-overlapping partition），你必须在构造子图时保存 node_idx（原始节点 ids）。\n",
    "# 假设你已经把 node_idx 存在每个 subgraph（名称为 'node_idx'），否则需要在划分时保存。\n",
    "\n",
    "# 我这里实现一个 merge（非重叠子图或平均策略），先根据 node_idx 填 features 和 edges\n",
    "def merge_subgraphs_to_full(modified_graph_list, num_nodes, feature_dim=None, threshold=0.5):\n",
    "    # features\n",
    "    # assume every sg.x shape = (n_i, d) and sg.node_idx exists\n",
    "    d = feature_dim if feature_dim is not None else ensure_numpy(modified_graph_list[0].x).shape[1]\n",
    "    feats = np.zeros((num_nodes, d), dtype=np.float32)\n",
    "    feat_count = np.zeros((num_nodes,), dtype=np.int32)\n",
    "    rows = []\n",
    "    cols = []\n",
    "    data = []\n",
    "    labels = np.full((num_nodes,), -1, dtype=np.int64)\n",
    "    for sg in modified_graph_list:\n",
    "        if not hasattr(sg, 'node_idx'):\n",
    "            raise RuntimeError(\"每个子图必须包含 node_idx 用于拼回原图。请在 induced_graphs 时保存 node_idx。\")\n",
    "        node_idx = ensure_numpy(sg.node_idx).astype(np.int64)\n",
    "        x_np = ensure_numpy(sg.x)\n",
    "        for local_i, orig_i in enumerate(node_idx):\n",
    "            feats[orig_i] += x_np[local_i]\n",
    "            feat_count[orig_i] += 1\n",
    "        if hasattr(sg, 'y') and sg.y is not None:\n",
    "            y_np = ensure_numpy(sg.y).reshape(-1)\n",
    "                # 检查标签数量是否与节点数量匹配,\n",
    "            if len(y_np) == len(node_idx):\n",
    "                    # 标签数量与节点数量匹配，正常处理,\n",
    "                    for local_i, orig_i in enumerate(node_idx):\n",
    "                        labels[orig_i] = y_np[local_i]\n",
    "            elif len(y_np) == 1:\n",
    "                    # 只有一个标签，应用到所有节点（图级别标签）\n",
    "                    label_value = y_np[0]\n",
    "                    for orig_i in node_idx:\n",
    "                        labels[orig_i] = label_value\n",
    "            else:\n",
    "                    # 标签数量不匹配，跳过或报警告\n",
    "                    print(f\"警告: 子图标签数量 {len(y_np)} 与节点数量 {len(node_idx)} 不匹配，跳过标签处理\")\n",
    "        # adjacency\n",
    "        adj_local = sg.adj\n",
    "        if isinstance(adj_local, torch.Tensor):\n",
    "            adj_local = adj_local.detach().cpu().numpy()\n",
    "        r_local, c_local = np.nonzero(adj_local)\n",
    "        rows.extend(node_idx[r_local].tolist())\n",
    "        cols.extend(node_idx[c_local].tolist())\n",
    "        data.extend(adj_local[r_local, c_local].tolist())\n",
    "    # average features where multiple assignments\n",
    "    nonzero = feat_count > 0\n",
    "    feats[nonzero] = feats[nonzero] / feat_count[nonzero][:, None]\n",
    "    # build sparse adj\n",
    "    adj_coo = sp.coo_matrix((np.array(data, dtype=np.float64), (np.array(rows), np.array(cols))),\n",
    "                            shape=(num_nodes, num_nodes))\n",
    "    adj_coo.setdiag(0)\n",
    "    adj_coo = adj_coo.tocsr()\n",
    "    adj_coo.eliminate_zeros()\n",
    "    adj_coo = adj_coo.maximum(adj_coo.T)  # 保证对称\n",
    "    # 二值化\n",
    "    adj_bin = (adj_coo > threshold).astype(np.int8)\n",
    "    return adj_bin.tocsr(), feats, labels\n",
    "\n",
    "# helper ensure_numpy\n",
    "def ensure_numpy(x):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x.detach().cpu().numpy()\n",
    "    return np.array(x)\n",
    "\n",
    "# 这里 num_nodes 要设为原始大图节点数（例如 data.x.shape[0]）\n",
    "num_nodes = data.x.shape[0]   # 你在 notebook 最开始加载的 data\n",
    "adj_final, feats_final, labels_final = merge_subgraphs_to_full(modified_graph_list, num_nodes, feature_dim=data.x.shape[1], threshold=0.5)\n",
    "\n",
    "# 保存为 npz（csr components + features + labels）\n",
    "np.savez_compressed('modified_full_graph.npz',\n",
    "                    adj_data=adj_final.data,\n",
    "                    adj_indices=adj_final.indices,\n",
    "                    adj_indptr=adj_final.indptr,\n",
    "                    adj_shape=adj_final.shape,\n",
    "                    features=feats_final.astype(np.float32),\n",
    "                    labels=labels_final.astype(np.int64))\n",
    "print(\"Saved modified_full_graph.npz\")\n",
    "\n",
    "\n",
    "# 同时保存为标准稀疏矩阵格式，兼容 DeepRobust\n",
    "import scipy.sparse as sp\n",
    "sp.save_npz('pubmed_mod_adj_005.npz', adj_final)\n",
    "print(\"Saved pubmed_mod_adj_005.npz (sparse matrix format)\")\n",
    "print(\"Saved pubmed_mod_adj_005.npz (sparse matrix format)\")\n",
    "# 验证保存的文件\n",
    "try:\n",
    "    test_adj = sp.load_npz('pubmed_mod_adj_005.npz')\n",
    "    print(f\"验证成功: pubmed_mod_adj_005.npz - 形状: {test_adj.shape}, 类型: {type(test_adj)}\")\n",
    "except Exception as e:\n",
    "    print(f\"验证失败: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T13:21:06.523533Z",
     "iopub.status.busy": "2025-09-05T13:21:06.523211Z",
     "iopub.status.idle": "2025-09-05T13:21:06.527251Z",
     "shell.execute_reply": "2025-09-05T13:21:06.526636Z",
     "shell.execute_reply.started": "2025-09-05T13:21:06.523506Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#在上述实验中可以发现需要较小的batch_size以支持meta-gradient的计算(e.g., batch_size=16); 如果太大则会出现Out-of-Memory, 因此在这里记录一下梯度图空间复杂度的理论分析：\n",
    "\n",
    "#假设现在有m个子图，平均每个图有n个节点，那么对于一个epoch来说，有m/batch_size个batch;\n",
    "\n",
    "#由于需要拼接整个batch的子图成一个大图，那么这个大图的邻接矩阵规模为 (n * batch_size)^2\n",
    "\n",
    "#综上, 存储的梯度图理论空间复杂度为：\n",
    "#O(m/batch_size*(n*batch_size)^2) = O(m*n^2*batch_size)\n",
    "\n",
    "#进一步考虑到完整的surrogate_training有k个epoch,那么整个surrogate_training的空间复杂度为：\n",
    "#O(k*m*n^2*batch_size)\n",
    "\n",
    "#因此过大的batch_size必然导致过大的内存开销\n",
    "#但如果batch_size过小, 比如极端情况下batch_size=1, 那么理论上讲导致surrogate_training过程过于“琐碎”, 无法感知到训练的全局方向。（TODO, 需要进一步做一个实验）\n",
    "#上面问题更新:目前部分实验做下来batch_size不会特别影响surrogate_training的效果,但batch_size过小将导致更长的开销时间（TODO, 再进一步做一个实验）\n",
    "\n",
    "#现在分析node_injection的理论空间复杂度:\n",
    "#进一步假设注入的节点个数为原图个数的b%,那么一共有m*n*b%个注入节点,每个注入节点只考虑添加到一个子图,因此优化节点注入位置的拓扑有n条,那么需要元梯度的拓扑扰动总数为m*n^2*b%\n",
    "#如果同时也考虑优化节点的d维特征,那么需要元梯度的特征总数为m*n*d*b%\n",
    "#整个surrogate_training的空间复杂度为:\n",
    "#O(k*m*n*(n+d)*b%)\n",
    "\n",
    "#分析O(k*m*n^2*batch_size)和O(k*m*n*(n+d)*b%)大小, 即比较n*batch_size和（n+d）*b%\n",
    "#往往为了不同任务域迁移,需要PCA降维,d不会过大，如100维\n",
    "#因此显然 n*batch_size >>（n+d）*b%\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "GPL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
