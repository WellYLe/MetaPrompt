{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-05T13:20:34.905828Z",
     "iopub.status.busy": "2025-09-05T13:20:34.905497Z",
     "iopub.status.idle": "2025-09-05T13:20:35.173707Z",
     "shell.execute_reply": "2025-09-05T13:20:35.172902Z",
     "shell.execute_reply.started": "2025-09-05T13:20:34.905802Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting pandas\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/98/af/7be05277859a7bc399da8ba68b88c96b27b48740b6cf49688899c6eb4176/pandas-2.3.3-cp39-cp39-win_amd64.whl (11.4 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/81/c4/34e93fe5f5429d7570ec1fa436f1986fb1f00c3e0f43a589fe2bbcd22c3f/pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/5c/23/c7abc0ca0a1526a0774eca151daeb8de62ec457e77262b66b359c3c7679e/tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "\n",
      "   ---------------------------------------- 0/3 [pytz]\n",
      "   ---------------------------------------- 0/3 [pytz]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   ---------------------------------------- 3/3 [pandas]\n",
      "\n",
      "Successfully installed pandas-2.3.3 pytz-2025.2 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "!pip install pandas numpy \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T13:20:35.175101Z",
     "iopub.status.busy": "2025-09-05T13:20:35.174770Z",
     "iopub.status.idle": "2025-09-05T13:20:40.539853Z",
     "shell.execute_reply": "2025-09-05T13:20:40.538891Z",
     "shell.execute_reply.started": "2025-09-05T13:20:35.175082Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting torch_geometric\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/03/9f/157e913626c1acfb3b19ce000b1a6e4e4fb177c0bc0ea0c67ca5bd714b5a/torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "Collecting aiohttp (from torch_geometric)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ad/a9/d47e7873175a4d8aed425f2cdea2df700b2dd44fac024ffbd83455a69a50/aiohttp-3.13.2-cp39-cp39-win_amd64.whl (456 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch_geometric) (2025.9.0)\n",
      "Collecting jinja2 (from torch_geometric)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/62/a1/3d680cbfd5f4b8f15abc1d571870c5fc3e594bb582bc3b64ea099db13e56/jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch_geometric) (2.0.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch_geometric) (7.0.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch_geometric) (3.2.4)\n",
      "Collecting requests (from torch_geometric)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/1e/db/4254e3eabe8020b458f1a747140d32277ec7a271daf1d235b70dc0b4e6e3/requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Collecting tqdm (from torch_geometric)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp->torch_geometric)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/0f/15/5bf3b99495fb160b63f95972b81750f18f7f4e02ad051373b669d17d44f2/aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp->torch_geometric)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/fb/76/641ae371508676492379f16e2fa48f4e2c11741bd63c48be4b12a6b09cba/aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->torch_geometric)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/fe/ba/e2081de779ca30d473f21f5b30e0e737c438205440784c7dfc81efc2b029/async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->torch_geometric)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/3a/2a/7cc015f5b9f5db42b7d48157e23356022889fc354a2813c15934b7cb5c0e/attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->torch_geometric)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/79/bd/bcc926f87027fad5e59926ff12d136e1082a115025d33c032d1cd69ab377/frozenlist-1.8.0-cp39-cp39-win_amd64.whl (44 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->torch_geometric)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/af/01/547ffe9c2faec91c26965c152f3fea6cff068b6037401f61d310cc861ff4/multidict-6.7.0-cp39-cp39-win_amd64.whl (46 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->torch_geometric)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a4/45/d78d136c3a3d215677abb886785aae744da2c3005bcb99e58640c56529b1/propcache-0.4.1-cp39-cp39-win_amd64.whl (41 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->torch_geometric)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/fd/58/d00f7cad9eba20c4eefac2682f34661d1d1b3a942fc0092eb60e78cfb733/yarl-1.22.0-cp39-cp39-win_amd64.whl (87 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.14.1)\n",
      "Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp->torch_geometric)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/0e/61/66938bbb5fc52dbdf84594873d5b51fb1f7c7794e9c0f5bd885f30bc507b/idna-3.11-py3-none-any.whl (71 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from jinja2->torch_geometric) (3.0.3)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->torch_geometric)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d1/a9/6c040053909d9d1ef4fcab45fddec083aedc9052c10078339b47c8573ea8/charset_normalizer-3.4.4-cp39-cp39-win_amd64.whl (107 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->torch_geometric)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/a7/c2/fe1e52489ae3122415c51f387e221dd0773709bad6c6cdaa599e8a2c5185/urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->torch_geometric)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e4/37/af0d2ef3967ac0d6113837b44a4f0bfe1328c2b9763bd5b1744520e5cfed/certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from tqdm->torch_geometric) (0.4.6)\n",
      "Installing collected packages: urllib3, tqdm, propcache, multidict, jinja2, idna, frozenlist, charset_normalizer, certifi, attrs, async-timeout, aiohappyeyeballs, yarl, requests, aiosignal, aiohttp, torch_geometric\n",
      "\n",
      "   -- -------------------------------------  1/17 [tqdm]\n",
      "   --------- ------------------------------  4/17 [jinja2]\n",
      "   ----------- ----------------------------  5/17 [idna]\n",
      "   --------------------- ------------------  9/17 [attrs]\n",
      "   ------------------------- -------------- 11/17 [aiohappyeyeballs]\n",
      "   ------------------------------ --------- 13/17 [requests]\n",
      "   ----------------------------------- ---- 15/17 [aiohttp]\n",
      "   ----------------------------------- ---- 15/17 [aiohttp]\n",
      "   ------------------------------------- -- 16/17 [torch_geometric]\n",
      "   ------------------------------------- -- 16/17 [torch_geometric]\n",
      "   ------------------------------------- -- 16/17 [torch_geometric]\n",
      "   ------------------------------------- -- 16/17 [torch_geometric]\n",
      "   ------------------------------------- -- 16/17 [torch_geometric]\n",
      "   ------------------------------------- -- 16/17 [torch_geometric]\n",
      "   ------------------------------------- -- 16/17 [torch_geometric]\n",
      "   ------------------------------------- -- 16/17 [torch_geometric]\n",
      "   ------------------------------------- -- 16/17 [torch_geometric]\n",
      "   ------------------------------------- -- 16/17 [torch_geometric]\n",
      "   ------------------------------------- -- 16/17 [torch_geometric]\n",
      "   ------------------------------------- -- 16/17 [torch_geometric]\n",
      "   ------------------------------------- -- 16/17 [torch_geometric]\n",
      "   ---------------------------------------- 17/17 [torch_geometric]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 async-timeout-5.0.1 attrs-25.4.0 certifi-2025.10.5 charset_normalizer-3.4.4 frozenlist-1.8.0 idna-3.11 jinja2-3.1.6 multidict-6.7.0 propcache-0.4.1 requests-2.32.5 torch_geometric-2.6.1 tqdm-4.67.1 urllib3-2.5.0 yarl-1.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T13:20:40.541311Z",
     "iopub.status.busy": "2025-09-05T13:20:40.541009Z",
     "iopub.status.idle": "2025-09-05T13:20:50.529249Z",
     "shell.execute_reply": "2025-09-05T13:20:50.528592Z",
     "shell.execute_reply.started": "2025-09-05T13:20:40.541284Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting torch\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/b9/dc/1f1f621afe15e3c496e1e8f94f8903f75f87e7d642d5a985e92210cc208d/torch-2.8.0-cp39-cp39-win_amd64.whl (241.2 MB)\n",
      "Requirement already satisfied: filelock in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.8.0\n",
      "tensor([[0, 1, 0, 0, 1, 2],\n",
      "        [1, 2, 0, 0, 1, 2]])\n",
      "tensor([[0, 0, 1, 1, 2],\n",
      "        [0, 1, 1, 2, 2]])\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "from torch_geometric.datasets import Planetoid, Amazon, Reddit, WikiCS, Flickr, WebKB, Actor, PolBlogs, CitationFull\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.transforms import AddSelfLoops\n",
    "from torch_geometric.utils import subgraph, k_hop_subgraph\n",
    "import torch_geometric.transforms as T\n",
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch_geometric.nn import global_add_pool, global_max_pool, GlobalAttention, global_mean_pool\n",
    "from torch_geometric.nn.inits import glorot\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 0],\n",
    "                           [1, 2, 0]], dtype=torch.long)\n",
    "x = torch.tensor([[1,2,3],\n",
    "                 [4,5,6],\n",
    "                 [6,7,8]])\n",
    "y = torch.tensor([0,1,2])\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "# 创建 AddSelfLoops 转换\n",
    "add_self_loops = AddSelfLoops()\n",
    "# 应用转换\n",
    "data = add_self_loops(data)\n",
    "print(data.edge_index)\n",
    "data.edge_index = torch.unique(data.edge_index, dim=1)\n",
    "print(data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T13:20:50.531468Z",
     "iopub.status.busy": "2025-09-05T13:20:50.531052Z",
     "iopub.status.idle": "2025-09-05T13:20:50.662444Z",
     "shell.execute_reply": "2025-09-05T13:20:50.661579Z",
     "shell.execute_reply.started": "2025-09-05T13:20:50.531448Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\11326\\\\Desktop\\\\MetaPrompt'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T13:20:50.663825Z",
     "iopub.status.busy": "2025-09-05T13:20:50.663572Z",
     "iopub.status.idle": "2025-09-05T13:21:01.225417Z",
     "shell.execute_reply": "2025-09-05T13:21:01.224580Z",
     "shell.execute_reply.started": "2025-09-05T13:20:50.663803Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting scipy\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/3e/77/dab54fe647a08ee4253963bcd8f9cf17509c8ca64d6335141422fe2e2114/scipy-1.13.1-cp39-cp39-win_amd64.whl (46.2 MB)\n",
      "     ---------------------------------------- 0.0/46.2 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 3.4/46.2 MB 20.2 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 6.0/46.2 MB 15.4 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 8.9/46.2 MB 14.6 MB/s eta 0:00:03\n",
      "     -------- ------------------------------ 10.5/46.2 MB 12.8 MB/s eta 0:00:03\n",
      "     ---------- ---------------------------- 12.1/46.2 MB 13.3 MB/s eta 0:00:03\n",
      "     -------------- ------------------------ 17.3/46.2 MB 13.6 MB/s eta 0:00:03\n",
      "     -------------- ------------------------ 17.6/46.2 MB 13.3 MB/s eta 0:00:03\n",
      "     ----------------- --------------------- 21.2/46.2 MB 12.5 MB/s eta 0:00:02\n",
      "     -------------------- ------------------ 24.1/46.2 MB 12.6 MB/s eta 0:00:02\n",
      "     ----------------------- --------------- 27.5/46.2 MB 12.9 MB/s eta 0:00:02\n",
      "     ------------------------- ------------- 30.1/46.2 MB 12.9 MB/s eta 0:00:02\n",
      "     --------------------------- ----------- 33.0/46.2 MB 12.9 MB/s eta 0:00:02\n",
      "     ----------------------------- --------- 34.9/46.2 MB 12.8 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 36.2/46.2 MB 12.6 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 39.8/46.2 MB 12.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 43.8/46.2 MB 12.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  46.1/46.2 MB 12.9 MB/s eta 0:00:01\n",
      "     --------------------------------------- 46.2/46.2 MB 12.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from scipy) (2.0.2)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.13.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n",
      "17500\n",
      "18000\n",
      "18500\n",
      "19000\n",
      "19500\n",
      "Data(x=[30, 500], edge_index=[2, 70], y=1, index=0) 0\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy\n",
    "def induced_graphs(data, device, smallest_size=10, largest_size=30):   # 构建诱导图的过程\n",
    "    induced_graph_list = []\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    for index in range(data.x.size(0)):\n",
    "        current_label = data.y[index].item()\n",
    "\n",
    "        current_hop = 2\n",
    "        subset, _, _, _ = k_hop_subgraph(node_idx=index, num_hops=current_hop,\n",
    "                                            edge_index=data.edge_index, relabel_nodes=True)\n",
    "        subset = subset\n",
    "\n",
    "        while len(subset) < smallest_size and current_hop < 5:\n",
    "            current_hop += 1\n",
    "            subset, _, _, _ = k_hop_subgraph(node_idx=index, num_hops=current_hop,\n",
    "                                                edge_index=data.edge_index)\n",
    "            \n",
    "        if len(subset) < smallest_size:\n",
    "            need_node_num = smallest_size - len(subset)\n",
    "            pos_nodes = torch.argwhere(data.y == int(current_label))   # Test data may leak\n",
    "            pos_nodes = pos_nodes.to('cpu')\n",
    "            subset = subset.to('cpu')\n",
    "            candidate_nodes = torch.from_numpy(np.setdiff1d(pos_nodes.numpy(), subset.numpy()))\n",
    "            candidate_nodes = candidate_nodes[torch.randperm(candidate_nodes.shape[0])][0:need_node_num]\n",
    "            subset = torch.cat([torch.flatten(subset), torch.flatten(candidate_nodes)])\n",
    "\n",
    "        if len(subset) > largest_size:\n",
    "            subset = subset[torch.randperm(subset.shape[0])][0:largest_size - 1]\n",
    "            subset = torch.unique(torch.cat([torch.LongTensor([index]).to(device), torch.flatten(subset).to(device)]))\n",
    "\n",
    "        subset = subset.to(device)\n",
    "        sub_edge_index, _ = subgraph(subset, data.edge_index, relabel_nodes=True)\n",
    "        sub_edge_index = sub_edge_index.to(device)\n",
    "\n",
    "        x = data.x[subset]\n",
    "\n",
    "        induced_graph = Data(x=x, edge_index=sub_edge_index, y=data.y[index], index=index, node_idx=subset.cpu())\n",
    "        add_self_loops = AddSelfLoops()\n",
    "        induced_graph = add_self_loops(induced_graph)\n",
    "        induced_graph.edge_index = torch.unique(induced_graph.edge_index, dim=1)\n",
    "        induced_graph_list.append(induced_graph)\n",
    "        if index%500 == 0:\n",
    "            print(index)\n",
    "    return induced_graph_list\n",
    "\n",
    "\n",
    "transform_list = [T.AddSelfLoops(), T.ToUndirected(), T.NormalizeFeatures()]\n",
    "transform = T.Compose(transform_list)\n",
    "dataset = Planetoid(root='c:/Users/11326/Desktop/MetaPrompt', name='PubMed', transform=transform)\n",
    "data = dataset[0]\n",
    "graph_list = induced_graphs(data, 'cpu')\n",
    "print(graph_list[0],graph_list[0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T13:21:01.226791Z",
     "iopub.status.busy": "2025-09-05T13:21:01.226225Z",
     "iopub.status.idle": "2025-09-05T13:21:01.383748Z",
     "shell.execute_reply": "2025-09-05T13:21:01.383108Z",
     "shell.execute_reply.started": "2025-09-05T13:21:01.226758Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[30, 500], edge_index=[2, 70], y=1, index=0, adj=[30, 30])\n"
     ]
    }
   ],
   "source": [
    "def normalize_adj_tensor(adj):\n",
    "    # gcn的归一化邻接矩阵方法\n",
    "    D = torch.sum(adj, dim=1)\n",
    "    D_inv = torch.pow(D, -1 / 2)\n",
    "    D_inv[torch.isinf(D_inv)] = 0.\n",
    "    D_mat_inv = torch.diag(D_inv)\n",
    "    adj_norm = D_mat_inv @ adj @ D_mat_inv  # GCN的归一化方式\n",
    "    return adj_norm\n",
    "\n",
    "def edge_index_to_adjacency_matrix(edge_index, num_nodes, undirected=True, device='cpu'):  \n",
    "    # 将edge_indedx转化为邻接矩阵\n",
    "    # 构建一个大小为 (num_nodes, num_nodes) 的零矩阵  \n",
    "    adjacency_matrix = torch.zeros(num_nodes, num_nodes, dtype=torch.uint8).to(device)\n",
    "      \n",
    "    # 使用索引广播机制，一次性将边索引映射到邻接矩阵的相应位置上  \n",
    "    if undirected:\n",
    "        adjacency_matrix[edge_index[0], edge_index[1]] = 1  \n",
    "        adjacency_matrix[edge_index[1], edge_index[0]] = 1  \n",
    "    else:\n",
    "        adjacency_matrix[edge_index[0], edge_index[1]] = 1\n",
    "    return adjacency_matrix\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "size_buffer = []\n",
    "for graph in graph_list:\n",
    "    size_buffer.append(graph.x.shape[0])\n",
    "    adj = edge_index_to_adjacency_matrix(graph.edge_index, graph.x.shape[0])\n",
    "    graph.adj = adj\n",
    "\n",
    "print(graph_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T13:21:01.384837Z",
     "iopub.status.busy": "2025-09-05T13:21:01.384534Z",
     "iopub.status.idle": "2025-09-05T13:21:01.394604Z",
     "shell.execute_reply": "2025-09-05T13:21:01.393841Z",
     "shell.execute_reply.started": "2025-09-05T13:21:01.384809Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, graph_list):\n",
    "        self.graph_list = graph_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graph_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graph_list[idx]\n",
    "\n",
    "class SequentialGraphLoader(DataLoader):\n",
    "    def __init__(self, graph_list, batch_size=1):\n",
    "        dataset = GraphDataset(graph_list)\n",
    "        super(SequentialGraphLoader, self).__init__(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.dataset), self.batch_size):\n",
    "            batch = self.dataset[i:i+self.batch_size]\n",
    "            yield self.merge_graphs(batch)\n",
    "\n",
    "    def merge_graphs(self, batch):\n",
    "        # 合并子图的特征矩阵和邻接矩阵\n",
    "        x_buffer = []\n",
    "        adj_list = []\n",
    "        y_buffer = []\n",
    "        batch_sizes = []\n",
    "        batch_indexs = []\n",
    "        graph_indexs = []\n",
    "\n",
    "        for i, graph in enumerate(batch):\n",
    "            x = graph.x\n",
    "            adj = graph.adj\n",
    "            y = graph.y.unsqueeze(0)  # 确保 y 是二维张量\n",
    "            x_buffer.append(x)\n",
    "            adj_list.append(adj)\n",
    "            y_buffer.append(y)\n",
    "            batch_sizes.append(x.shape[0])  # 存储子图的大小\n",
    "            batch_indexs = batch_indexs + [i] * x.shape[0]\n",
    "            graph_indexs.append(graph.index)\n",
    "\n",
    "        # 将特征矩阵堆叠\n",
    "        x_combined = torch.cat(x_buffer, dim=0)  # 合并特征矩阵\n",
    "        num_nodes = x_combined.size(0)  # 所有节点的总数\n",
    "        \n",
    "        # 构建大的邻接矩阵\n",
    "        adj_combined = torch.zeros(num_nodes, num_nodes, device=x_combined.device)\n",
    "        start = 0\n",
    "        for i in range(len(batch)):\n",
    "            end = start + batch_sizes[i]\n",
    "            adj_combined[start:end, start:end] = adj_list[i]  # 填充对应的子图邻接矩阵\n",
    "            start = end\n",
    "\n",
    "        y_combined = torch.cat(y_buffer, dim=0)  # 合并标签\n",
    "        batch_indexs = torch.tensor(batch_indexs)\n",
    "\n",
    "        return x_combined, adj_combined, y_combined, batch_sizes, batch_indexs, graph_indexs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T13:21:01.396107Z",
     "iopub.status.busy": "2025-09-05T13:21:01.395431Z",
     "iopub.status.idle": "2025-09-05T13:21:06.522402Z",
     "shell.execute_reply": "2025-09-05T13:21:06.521691Z",
     "shell.execute_reply.started": "2025-09-05T13:21:01.396078Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_num: 0\n",
      "epoch_num: 1\n",
      "epoch_num: 2\n",
      "epoch_num: 3\n",
      "epoch_num: 4\n",
      "epoch_num: 5\n",
      "epoch_num: 6\n",
      "epoch_num: 7\n",
      "epoch_num: 8\n",
      "epoch_num: 9\n",
      "done\n",
      "tensor([[ 0.0000e+00,  1.0090e-02, -2.5300e-02, -2.8497e-02, -2.2902e-01,\n",
      "         -2.2669e-02,  2.7803e-01, -1.5354e-04, -4.5807e-02, -1.0042e-01,\n",
      "          1.2119e-01, -3.6147e-02,  2.9822e-01,  5.5859e-01, -1.0930e-01,\n",
      "         -1.1837e-01,  2.8485e-01, -1.4685e-02,  4.9613e-02, -4.1784e-02,\n",
      "         -4.9519e-02,  4.2553e-02, -3.3521e-01, -7.5936e-02,  1.5476e-01,\n",
      "         -2.3705e-02, -5.0101e-02, -1.3405e-01,  7.6391e-02],\n",
      "        [-1.0090e-02,  0.0000e+00, -3.5390e-02, -3.8587e-02, -2.3911e-01,\n",
      "         -3.2758e-02,  2.6794e-01, -1.0243e-02, -5.5897e-02, -1.1051e-01,\n",
      "          1.1110e-01, -4.6237e-02,  2.8813e-01,  5.4850e-01, -1.1939e-01,\n",
      "         -1.2846e-01,  2.7476e-01, -2.4775e-02,  3.9523e-02, -5.1873e-02,\n",
      "         -5.9609e-02,  3.2463e-02, -3.4530e-01, -8.6025e-02,  1.4467e-01,\n",
      "         -3.3795e-02, -6.0191e-02, -1.4414e-01,  6.6301e-02],\n",
      "        [ 2.5300e-02,  3.5390e-02,  0.0000e+00, -3.1963e-03, -2.0372e-01,\n",
      "          2.6318e-03,  3.0333e-01,  2.5147e-02, -2.0507e-02, -7.5117e-02,\n",
      "          1.4649e-01, -1.0847e-02,  3.2352e-01,  5.8389e-01, -8.4004e-02,\n",
      "         -9.3074e-02,  3.1015e-01,  1.0615e-02,  7.4913e-02, -1.6483e-02,\n",
      "         -2.4219e-02,  6.7853e-02, -3.0991e-01, -5.0635e-02,  1.8006e-01,\n",
      "          1.5954e-03, -2.4801e-02, -1.0875e-01,  1.0169e-01],\n",
      "        [ 2.8497e-02,  3.8587e-02,  3.1963e-03,  0.0000e+00, -2.0053e-01,\n",
      "          5.8282e-03,  3.0653e-01,  2.8343e-02, -1.7310e-02, -7.1921e-02,\n",
      "          1.4969e-01, -7.6506e-03,  3.2671e-01,  5.8709e-01, -8.0808e-02,\n",
      "         -8.9878e-02,  3.1335e-01,  1.3812e-02,  7.8110e-02, -1.3287e-02,\n",
      "         -2.1023e-02,  7.1050e-02, -3.0671e-01, -4.7439e-02,  1.8326e-01,\n",
      "          4.7917e-03, -2.1604e-02, -1.0555e-01,  1.0489e-01],\n",
      "        [ 2.2902e-01,  2.3911e-01,  2.0372e-01,  2.0053e-01,  0.0000e+00,\n",
      "          2.0635e-01,  5.0705e-01,  2.2887e-01,  1.8322e-01,  1.2861e-01,\n",
      "          3.5021e-01,  1.9288e-01,  5.2724e-01,  7.8761e-01,  1.1972e-01,\n",
      "          1.1065e-01,  5.1387e-01,  2.1434e-01,  2.7864e-01,  1.8724e-01,\n",
      "          1.7950e-01,  2.7158e-01, -1.0619e-01,  1.5309e-01,  3.8378e-01,\n",
      "          2.0532e-01,  1.7892e-01,  9.4972e-02,  3.0541e-01],\n",
      "        [ 2.2669e-02,  3.2758e-02, -2.6318e-03, -5.8282e-03, -2.0635e-01,\n",
      "          0.0000e+00,  3.0070e-01,  2.2515e-02, -2.3138e-02, -7.7749e-02,\n",
      "          1.4386e-01, -1.3479e-02,  3.2089e-01,  5.8126e-01, -8.6636e-02,\n",
      "         -9.5706e-02,  3.0752e-01,  7.9834e-03,  7.2282e-02, -1.9115e-02,\n",
      "         -2.6851e-02,  6.5221e-02, -3.1254e-01, -5.3267e-02,  1.7743e-01,\n",
      "         -1.0364e-03, -2.7432e-02, -1.1138e-01,  9.9060e-02],\n",
      "        [-1.9178e-01, -1.8517e-01, -2.0836e-01, -2.1046e-01, -3.4187e-01,\n",
      "         -2.0664e-01,  0.0000e+00, -1.9188e-01, -2.2180e-01, -2.5759e-01,\n",
      "         -1.1236e-01, -2.1547e-01,  4.1297e-03,  1.7428e-01, -2.6341e-01,\n",
      "         -2.6936e-01, -7.2436e-03, -2.0140e-01, -1.5927e-01, -2.1916e-01,\n",
      "         -2.2423e-01, -1.6390e-01, -4.1145e-01, -2.4154e-01, -8.7407e-02,\n",
      "         -2.0732e-01, -2.2461e-01, -2.7963e-01, -1.4172e-01],\n",
      "        [ 1.5354e-04,  1.0243e-02, -2.5147e-02, -2.8343e-02, -2.2887e-01,\n",
      "         -2.2515e-02,  2.7818e-01,  0.0000e+00, -4.5653e-02, -1.0026e-01,\n",
      "          1.2135e-01, -3.5994e-02,  2.9837e-01,  5.5874e-01, -1.0915e-01,\n",
      "         -1.1822e-01,  2.8500e-01, -1.4532e-02,  4.9767e-02, -4.1630e-02,\n",
      "         -4.9366e-02,  4.2706e-02, -3.3506e-01, -7.5782e-02,  1.5491e-01,\n",
      "         -2.3551e-02, -4.9947e-02, -1.3390e-01,  7.6545e-02],\n",
      "        [ 4.5807e-02,  5.5897e-02,  2.0507e-02,  1.7310e-02, -1.8322e-01,\n",
      "          2.3138e-02,  3.2384e-01,  4.5653e-02,  0.0000e+00, -5.4610e-02,\n",
      "          1.6700e-01,  9.6597e-03,  3.4402e-01,  6.0440e-01, -6.3497e-02,\n",
      "         -7.2567e-02,  3.3066e-01,  3.1122e-02,  9.5420e-02,  4.0233e-03,\n",
      "         -3.7124e-03,  8.8360e-02, -2.8940e-01, -3.0129e-02,  2.0057e-01,\n",
      "          2.2102e-02, -4.2939e-03, -8.8244e-02,  1.2220e-01],\n",
      "        [ 1.0042e-01,  1.1051e-01,  7.5117e-02,  7.1921e-02, -1.2861e-01,\n",
      "          7.7749e-02,  3.7845e-01,  1.0026e-01,  5.4610e-02,  0.0000e+00,\n",
      "          2.2161e-01,  6.4270e-02,  3.9863e-01,  6.5901e-01, -8.8869e-03,\n",
      "         -1.7957e-02,  3.8527e-01,  8.5732e-02,  1.5003e-01,  5.8634e-02,\n",
      "          5.0898e-02,  1.4297e-01, -2.3479e-01,  2.4482e-02,  2.5518e-01,\n",
      "          7.6712e-02,  5.0316e-02, -3.3633e-02,  1.7681e-01],\n",
      "        [-1.2119e-01, -1.1110e-01, -1.4649e-01, -1.4969e-01, -3.5021e-01,\n",
      "         -1.4386e-01,  1.5684e-01, -1.2135e-01, -1.6700e-01, -2.2161e-01,\n",
      "          0.0000e+00, -1.5734e-01,  1.7703e-01,  4.3740e-01, -2.3050e-01,\n",
      "         -2.3957e-01,  1.6366e-01, -1.3588e-01, -7.1579e-02, -1.6298e-01,\n",
      "         -1.7071e-01, -7.8639e-02, -4.5640e-01, -1.9713e-01,  3.3567e-02,\n",
      "         -1.4490e-01, -1.7129e-01, -2.5524e-01, -4.4801e-02],\n",
      "        [ 3.6147e-02,  4.6237e-02,  1.0847e-02,  7.6506e-03, -1.9288e-01,\n",
      "          1.3479e-02,  3.1418e-01,  3.5994e-02, -9.6597e-03, -6.4270e-02,\n",
      "          1.5734e-01,  0.0000e+00,  3.3436e-01,  5.9474e-01, -7.3157e-02,\n",
      "         -8.2227e-02,  3.2100e-01,  2.1462e-02,  8.5760e-02, -5.6364e-03,\n",
      "         -1.3372e-02,  7.8700e-02, -2.9906e-01, -3.9788e-02,  1.9091e-01,\n",
      "          1.2442e-02, -1.3954e-02, -9.7903e-02,  1.1254e-01],\n",
      "        [-2.0127e-01, -1.9466e-01, -2.1785e-01, -2.1994e-01, -3.5135e-01,\n",
      "         -2.1612e-01, -1.8238e-02, -2.0137e-01, -2.3129e-01, -2.6707e-01,\n",
      "         -1.2185e-01, -2.2496e-01,  0.0000e+00,  1.6479e-01, -2.7290e-01,\n",
      "         -2.7884e-01, -1.6730e-02, -2.1089e-01, -1.6875e-01, -2.2865e-01,\n",
      "         -2.3372e-01, -1.7338e-01, -4.2094e-01, -2.5103e-01, -9.6894e-02,\n",
      "         -2.1680e-01, -2.3410e-01, -2.8912e-01, -1.5121e-01],\n",
      "        [-5.5859e-01, -5.4850e-01, -5.8389e-01, -5.8709e-01, -7.8761e-01,\n",
      "         -5.8126e-01, -2.8056e-01, -5.5874e-01, -6.0440e-01, -6.5901e-01,\n",
      "         -4.3740e-01, -5.9474e-01, -2.6037e-01,  0.0000e+00, -6.6790e-01,\n",
      "         -6.7697e-01, -2.7374e-01, -5.7328e-01, -5.0898e-01, -6.0037e-01,\n",
      "         -6.0811e-01, -5.1604e-01, -8.9380e-01, -6.3453e-01, -4.0383e-01,\n",
      "         -5.8230e-01, -6.0869e-01, -6.9264e-01, -4.8220e-01],\n",
      "        [ 1.0930e-01,  1.1939e-01,  8.4004e-02,  8.0808e-02, -1.1972e-01,\n",
      "          8.6636e-02,  3.8733e-01,  1.0915e-01,  6.3497e-02,  8.8869e-03,\n",
      "          2.3050e-01,  7.3157e-02,  4.0752e-01,  6.6790e-01,  0.0000e+00,\n",
      "         -9.0700e-03,  3.9415e-01,  9.4619e-02,  1.5892e-01,  6.7521e-02,\n",
      "          5.9785e-02,  1.5186e-01, -2.2591e-01,  3.3369e-02,  2.6406e-01,\n",
      "          8.5599e-02,  5.9203e-02, -2.4746e-02,  1.8570e-01],\n",
      "        [ 1.1837e-01,  1.2846e-01,  9.3074e-02,  8.9878e-02, -1.1065e-01,\n",
      "          9.5706e-02,  3.9640e-01,  1.1822e-01,  7.2567e-02,  1.7957e-02,\n",
      "          2.3957e-01,  8.2227e-02,  4.1659e-01,  6.7697e-01,  9.0700e-03,\n",
      "          0.0000e+00,  4.0322e-01,  1.0369e-01,  1.6799e-01,  7.6591e-02,\n",
      "          6.8855e-02,  1.6093e-01, -2.1684e-01,  4.2439e-02,  2.7313e-01,\n",
      "          9.4669e-02,  6.8273e-02, -1.5676e-02,  1.9477e-01],\n",
      "        [-1.4169e-01, -1.3586e-01, -1.5630e-01, -1.5815e-01, -2.7399e-01,\n",
      "         -1.5478e-01,  1.7678e-02, -1.4178e-01, -1.6815e-01, -1.9970e-01,\n",
      "         -7.1679e-02, -1.6257e-01,  2.9862e-02,  1.8099e-01, -2.0483e-01,\n",
      "         -2.1007e-01,  0.0000e+00, -1.5017e-01, -1.1303e-01, -1.6582e-01,\n",
      "         -1.7029e-01, -1.1711e-01, -3.3533e-01, -1.8555e-01, -5.6723e-02,\n",
      "         -1.5538e-01, -1.7063e-01, -2.1912e-01, -9.7559e-02],\n",
      "        [ 1.4685e-02,  2.4775e-02, -1.0615e-02, -1.3812e-02, -2.1434e-01,\n",
      "         -7.9834e-03,  2.9272e-01,  1.4532e-02, -3.1122e-02, -8.5732e-02,\n",
      "          1.3588e-01, -2.1462e-02,  3.1290e-01,  5.7328e-01, -9.4619e-02,\n",
      "         -1.0369e-01,  2.9953e-01,  0.0000e+00,  6.4298e-02, -2.7099e-02,\n",
      "         -3.4834e-02,  5.7238e-02, -3.2053e-01, -6.1251e-02,  1.6944e-01,\n",
      "         -9.0199e-03, -3.5416e-02, -1.1937e-01,  9.1076e-02],\n",
      "        [-4.9613e-02, -3.9523e-02, -7.4913e-02, -7.8110e-02, -2.7864e-01,\n",
      "         -7.2282e-02,  2.2842e-01, -4.9767e-02, -9.5420e-02, -1.5003e-01,\n",
      "          7.1579e-02, -8.5760e-02,  2.4860e-01,  5.0898e-01, -1.5892e-01,\n",
      "         -1.6799e-01,  2.3524e-01, -6.4298e-02,  0.0000e+00, -9.1397e-02,\n",
      "         -9.9132e-02, -7.0602e-03, -3.8482e-01, -1.2555e-01,  1.0515e-01,\n",
      "         -7.3318e-02, -9.9714e-02, -1.8366e-01,  2.6778e-02],\n",
      "        [ 4.1784e-02,  5.1873e-02,  1.6483e-02,  1.3287e-02, -1.8724e-01,\n",
      "          1.9115e-02,  3.1981e-01,  4.1630e-02, -4.0233e-03, -5.8634e-02,\n",
      "          1.6298e-01,  5.6364e-03,  3.4000e-01,  6.0037e-01, -6.7521e-02,\n",
      "         -7.6591e-02,  3.2663e-01,  2.7099e-02,  9.1397e-02,  0.0000e+00,\n",
      "         -7.7357e-03,  8.4337e-02, -2.9343e-01, -3.4152e-02,  1.9654e-01,\n",
      "          1.8079e-02, -8.3172e-03, -9.2267e-02,  1.1817e-01],\n",
      "        [ 4.9519e-02,  5.9609e-02,  2.4219e-02,  2.1023e-02, -1.7950e-01,\n",
      "          2.6851e-02,  3.2755e-01,  4.9366e-02,  3.7124e-03, -5.0898e-02,\n",
      "          1.7071e-01,  1.3372e-02,  3.4774e-01,  6.0811e-01, -5.9785e-02,\n",
      "         -6.8855e-02,  3.3437e-01,  3.4834e-02,  9.9132e-02,  7.7357e-03,\n",
      "          0.0000e+00,  9.2072e-02, -2.8569e-01, -2.6416e-02,  2.0428e-01,\n",
      "          2.5814e-02, -5.8156e-04, -8.4531e-02,  1.2591e-01],\n",
      "        [-4.2553e-02, -3.2463e-02, -6.7853e-02, -7.1050e-02, -2.7158e-01,\n",
      "         -6.5221e-02,  2.3548e-01, -4.2706e-02, -8.8360e-02, -1.4297e-01,\n",
      "          7.8639e-02, -7.8700e-02,  2.5566e-01,  5.1604e-01, -1.5186e-01,\n",
      "         -1.6093e-01,  2.4230e-01, -5.7238e-02,  7.0602e-03, -8.4337e-02,\n",
      "         -9.2072e-02,  0.0000e+00, -3.7776e-01, -1.1849e-01,  1.1221e-01,\n",
      "         -6.6258e-02, -9.2654e-02, -1.7660e-01,  3.3838e-02],\n",
      "        [ 3.3521e-01,  3.4530e-01,  3.0991e-01,  3.0671e-01,  1.0619e-01,\n",
      "          3.1254e-01,  6.1324e-01,  3.3506e-01,  2.8940e-01,  2.3479e-01,\n",
      "          4.5640e-01,  2.9906e-01,  6.3343e-01,  8.9380e-01,  2.2591e-01,\n",
      "          2.1684e-01,  6.2006e-01,  3.2053e-01,  3.8482e-01,  2.9343e-01,\n",
      "          2.8569e-01,  3.7776e-01,  0.0000e+00,  2.5927e-01,  4.8997e-01,\n",
      "          3.1151e-01,  2.8511e-01,  2.0116e-01,  4.1160e-01],\n",
      "        [ 7.5936e-02,  8.6025e-02,  5.0635e-02,  4.7439e-02, -1.5309e-01,\n",
      "          5.3267e-02,  3.5397e-01,  7.5782e-02,  3.0129e-02, -2.4482e-02,\n",
      "          1.9713e-01,  3.9788e-02,  3.7415e-01,  6.3453e-01, -3.3369e-02,\n",
      "         -4.2439e-02,  3.6078e-01,  6.1251e-02,  1.2555e-01,  3.4152e-02,\n",
      "          2.6416e-02,  1.1849e-01, -2.5927e-01,  0.0000e+00,  2.3069e-01,\n",
      "          5.2231e-02,  2.5835e-02, -5.8115e-02,  1.5233e-01],\n",
      "        [-1.3385e-01, -1.2724e-01, -1.5043e-01, -1.5253e-01, -2.8394e-01,\n",
      "         -1.4871e-01,  4.9177e-02, -1.3395e-01, -1.6387e-01, -1.9966e-01,\n",
      "         -5.4432e-02, -1.5754e-01,  6.2058e-02,  2.3221e-01, -2.0548e-01,\n",
      "         -2.1143e-01,  5.0685e-02, -1.4348e-01, -1.0134e-01, -1.6124e-01,\n",
      "         -1.6630e-01, -1.0597e-01, -3.5353e-01, -1.8362e-01,  0.0000e+00,\n",
      "         -1.4939e-01, -1.6669e-01, -2.2170e-01, -8.3792e-02],\n",
      "        [ 2.3705e-02,  3.3795e-02, -1.5954e-03, -4.7917e-03, -2.0532e-01,\n",
      "          1.0364e-03,  3.0174e-01,  2.3551e-02, -2.2102e-02, -7.6712e-02,\n",
      "          1.4490e-01, -1.2442e-02,  3.2192e-01,  5.8230e-01, -8.5599e-02,\n",
      "         -9.4669e-02,  3.0855e-01,  9.0199e-03,  7.3318e-02, -1.8079e-02,\n",
      "         -2.5814e-02,  6.6258e-02, -3.1151e-01, -5.2231e-02,  1.7846e-01,\n",
      "          0.0000e+00, -2.6396e-02, -1.1035e-01,  1.0010e-01],\n",
      "        [ 5.0101e-02,  6.0191e-02,  2.4801e-02,  2.1604e-02, -1.7892e-01,\n",
      "          2.7432e-02,  3.2813e-01,  4.9947e-02,  4.2939e-03, -5.0316e-02,\n",
      "          1.7129e-01,  1.3954e-02,  3.4832e-01,  6.0869e-01, -5.9203e-02,\n",
      "         -6.8273e-02,  3.3495e-01,  3.5416e-02,  9.9714e-02,  8.3172e-03,\n",
      "          5.8156e-04,  9.2654e-02, -2.8511e-01, -2.5835e-02,  2.0486e-01,\n",
      "          2.6396e-02,  0.0000e+00, -8.3950e-02,  1.2649e-01],\n",
      "        [ 1.3405e-01,  1.4414e-01,  1.0875e-01,  1.0555e-01, -9.4972e-02,\n",
      "          1.1138e-01,  4.1208e-01,  1.3390e-01,  8.8244e-02,  3.3633e-02,\n",
      "          2.5524e-01,  9.7903e-02,  4.3227e-01,  6.9264e-01,  2.4746e-02,\n",
      "          1.5676e-02,  4.1890e-01,  1.1937e-01,  1.8366e-01,  9.2267e-02,\n",
      "          8.4531e-02,  1.7660e-01, -2.0116e-01,  5.8115e-02,  2.8881e-01,\n",
      "          1.1035e-01,  8.3950e-02,  0.0000e+00,  2.1044e-01],\n",
      "        [-7.6391e-02, -6.6301e-02, -1.0169e-01, -1.0489e-01, -3.0541e-01,\n",
      "         -9.9060e-02,  2.0164e-01, -7.6545e-02, -1.2220e-01, -1.7681e-01,\n",
      "          4.4801e-02, -1.1254e-01,  2.2183e-01,  4.8220e-01, -1.8570e-01,\n",
      "         -1.9477e-01,  2.0846e-01, -9.1076e-02, -2.6778e-02, -1.1817e-01,\n",
      "         -1.2591e-01, -3.3838e-02, -4.1160e-01, -1.5233e-01,  7.8368e-02,\n",
      "         -1.0010e-01, -1.2649e-01, -2.1044e-01,  0.0000e+00]])\n",
      "Saved modified_full_graph.npz\n",
      "Saved pubmed_mod_adj_005.npz (sparse matrix format)\n",
      "Saved pubmed_mod_adj_005.npz (sparse matrix format)\n",
      "验证成功: pubmed_mod_adj_005.npz - 形状: (19717, 19717), 类型: <class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Batch, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import math\n",
    "import copy\n",
    "\n",
    "modified_graph_list = copy.deepcopy(graph_list)\n",
    "adj_changes = [torch.nn.Parameter(torch.FloatTensor(size, size)) for size in size_buffer] # 对每个子图的扰动\n",
    "for adj_change in adj_changes:\n",
    "    adj_change.data.fill_(0)\n",
    "for modified_graph, graph, adj_change in zip(modified_graph_list, graph_list, adj_changes):\n",
    "    change_square = adj_change - torch.diag(torch.diag(adj_change, 0))\n",
    "    change_square = torch.clamp(change_square, -1, 1)\n",
    "    modified_graph.adj = change_square + graph.adj\n",
    "\n",
    "train_loader = SequentialGraphLoader(modified_graph_list[:800], batch_size=16) # 定义的Dataloader\n",
    "test_loader = SequentialGraphLoader(modified_graph_list[800:], batch_size=16)\n",
    "weights = []\n",
    "w_velocities = []\n",
    "hidden_sizes = [128 for i in range(2)]\n",
    "previous_size = 500\n",
    "out_dim = 7\n",
    "for ix, nhid in enumerate(hidden_sizes):\n",
    "    weight = torch.nn.Parameter(torch.FloatTensor(previous_size, nhid).to(device))\n",
    "    w_velocity = torch.zeros(weight.shape).to(device)\n",
    "    weights.append(weight)\n",
    "    w_velocities.append(w_velocity)\n",
    "    previous_size = nhid\n",
    "    \n",
    "output_weight = torch.nn.Parameter(torch.FloatTensor(previous_size, out_dim).to(device))\n",
    "output_w_velocity = torch.zeros(output_weight.shape).to(device)\n",
    "weights.append(output_weight)\n",
    "w_velocities.append(output_w_velocity)\n",
    "for w, v in zip(weights, w_velocities):\n",
    "    stdv = 1. / math.sqrt(w.size(1))\n",
    "    w.data.uniform_(-stdv, stdv)\n",
    "    v.data.fill_(0)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # 分类任务的损失函数\n",
    "\n",
    "\n",
    "#初始化参数,避免梯度爆炸\n",
    "for w, v in zip(weights, w_velocities):\n",
    "    stdv = 1. / math.sqrt(w.size(1))\n",
    "    w.data.uniform_(-stdv, stdv)\n",
    "    v.data.fill_(0)\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(\"epoch_num:\", epoch)\n",
    "    for x, adj, y, sizes, batch_indexs, graph_indexs in train_loader:\n",
    "        loss = 0.0\n",
    "        x, adj, y, batch_indexs = x.to(device), adj.to(device), y.to(device), batch_indexs.to(device)\n",
    "        adj_norm = normalize_adj_tensor(adj)\n",
    "        \n",
    "        # 图卷积\n",
    "        for i, w in enumerate(weights):\n",
    "            if i != len(weights)-1:\n",
    "                x = adj_norm @ x @ w\n",
    "            else:\n",
    "                x = global_mean_pool(x, batch_indexs) @ w\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = criterion(x, y)\n",
    "        assert torch.isnan(loss).any()==False, \"loss is NaN\"\n",
    "        if torch.isnan(loss).any():\n",
    "            raise ValueError(\"loss is NaN!\")\n",
    "        weight_grads = torch.autograd.grad(loss, weights, create_graph=True)\n",
    "        w_velocities = [0.9 * v + g for v, g in zip(w_velocities, weight_grads)]\n",
    "        weights = [w - 0.01 * v for w, v in zip(weights, w_velocities)]\n",
    "        \n",
    "total_loss = 0.0\n",
    "for x, adj, y, sizes, batch_indexs, graph_indexs in test_loader:\n",
    "    x, adj, y, batch_indexs = x.to(device), adj.to(device), y.to(device), batch_indexs.to(device)\n",
    "    adj_norm = normalize_adj_tensor(adj)\n",
    "    \n",
    "    # 图卷积\n",
    "    for i, w in enumerate(weights):\n",
    "        if i != len(weights)-1:\n",
    "            x = adj_norm @ x @ w\n",
    "        else:\n",
    "            x = global_mean_pool(x, batch_indexs) @ w\n",
    "        \n",
    "    # 累计损失\n",
    "    total_loss += criterion(x, y) * x.shape[0]\n",
    "\n",
    "total_loss.backward(retain_graph=False)\n",
    "\n",
    "# 提取元梯度\n",
    "adj_grads = [adj_change.grad for adj_change in adj_changes]\n",
    "\n",
    "# 验证形状\n",
    "for grad, adj_change in zip(adj_grads, adj_changes):\n",
    "    assert grad.shape == adj_change.shape\n",
    "print(\"done\")\n",
    "print(adj_grads[0])\n",
    "# -------------------------\n",
    "# 在 total_loss.backward(...) 和 adj_grads 之后运行\n",
    "# -------------------------\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# attack_ratio: 你在 adj_changes 定义处设定，比如 0.05 表示每个子图翻 / 注入 5% 的“可能边位”\n",
    "# 若你还没定义，请在这里设置（或改为从上面单元读取）\n",
    "attack_ratio = 0.25\n",
    "\n",
    "# adj_grads 已经存在（list of tensors，shape 与对应 adj_change 相同）\n",
    "# graph_list 与 modified_graph_list 在前面单元已定义\n",
    "adj_grads = [g.detach().cpu().numpy() for g in adj_grads]  # 转 numpy 便于处理\n",
    "\n",
    "def apply_budgeted_flips_to_subgraph(orig_adj, grad_mat, ratio):\n",
    "    \"\"\"\n",
    "    orig_adj: torch tensor 或 numpy 二值邻接 (n_i, n_i)\n",
    "    grad_mat: numpy ndarray, 对应 adj_change.grad 的绝对值敏感度矩阵 (n_i, n_i)\n",
    "    ratio: 比例 (0~1)，表示要翻转的边/位置占上三角（不含对角）的比例\n",
    "    返回: 修改后的二值邻接 numpy (n_i, n_i)\n",
    "    \"\"\"\n",
    "    if isinstance(orig_adj, torch.Tensor):\n",
    "        A = orig_adj.detach().cpu().numpy().astype(np.int8)\n",
    "    else:\n",
    "        A = np.array(orig_adj, dtype=np.int8)\n",
    "    n = A.shape[0]\n",
    "    # 只考虑上三角（i<j）的候选位置（无向图）\n",
    "    iu = np.triu_indices(n, k=1)\n",
    "    # score = abs(grad)\n",
    "    scores = np.abs(grad_mat[iu])\n",
    "    m = len(scores)\n",
    "    k = max(1, int(np.round(ratio * m)))  # 至少选 1 个\n",
    "    if k >= m:\n",
    "        top_idx = np.arange(m)\n",
    "    else:\n",
    "        top_idx = np.argpartition(-scores, k-1)[:k]  # top-k indices within iu\n",
    "    rows = iu[0][top_idx]\n",
    "    cols = iu[1][top_idx]\n",
    "    # flip edges at (rows, cols)\n",
    "    A_new = A.copy()\n",
    "    A_new[rows, cols] = 1 - A_new[rows, cols]  # flip: 1->0, 0->1\n",
    "    A_new[cols, rows] = A_new[rows, cols]      # 对称\n",
    "    # 保持对角为0\n",
    "    np.fill_diagonal(A_new, 0)\n",
    "    return A_new\n",
    "\n",
    "# 遍历每个子图，按比例把梯度大的位置翻转成最终的二值邻接\n",
    "for i, (sg, grad) in enumerate(zip(modified_graph_list, adj_grads)):\n",
    "    # sg.adj 可能是 torch.Tensor；把 grad 传进去\n",
    "    new_adj = apply_budgeted_flips_to_subgraph(sg.adj, grad, attack_ratio)\n",
    "    # 把 numpy 转回 torch（或保持 numpy，后面拼接时统一处理）\n",
    "    sg.adj = torch.from_numpy(new_adj).to(sg.x.device)\n",
    "\n",
    "# 至此 modified_graph_list 已经包含“最终二值化后的子图邻接”\n",
    "# 下一步：把子图拼回为一张大图并保存为 npz\n",
    "# 需要每个 subgraph 包含原图 node id 映射：graph.index（你的 induced_graph 保存了 index 字段）\n",
    "# 如果每个 subgraph 里有 attribute 'index' 为中心节点 id，可以用它和子图节点顺序做映射（若你在构造子图时保留了 node_idx 那更好）\n",
    "\n",
    "# 这里基于你的 induced_graphs 函数：每个 subgraph 的 .index = 中心节点（单个node）\n",
    "# 如果想要正确拼回原大图（non-overlapping partition），你必须在构造子图时保存 node_idx（原始节点 ids）。\n",
    "# 假设你已经把 node_idx 存在每个 subgraph（名称为 'node_idx'），否则需要在划分时保存。\n",
    "\n",
    "# 我这里实现一个 merge（非重叠子图或平均策略），先根据 node_idx 填 features 和 edges\n",
    "def merge_subgraphs_to_full(modified_graph_list, num_nodes, feature_dim=None, threshold=0.5):\n",
    "    # features\n",
    "    # assume every sg.x shape = (n_i, d) and sg.node_idx exists\n",
    "    d = feature_dim if feature_dim is not None else ensure_numpy(modified_graph_list[0].x).shape[1]\n",
    "    feats = np.zeros((num_nodes, d), dtype=np.float32)\n",
    "    feat_count = np.zeros((num_nodes,), dtype=np.int32)\n",
    "    rows = []\n",
    "    cols = []\n",
    "    data = []\n",
    "    labels = np.full((num_nodes,), -1, dtype=np.int64)\n",
    "    for sg in modified_graph_list:\n",
    "        if not hasattr(sg, 'node_idx'):\n",
    "            raise RuntimeError(\"每个子图必须包含 node_idx 用于拼回原图。请在 induced_graphs 时保存 node_idx。\")\n",
    "        node_idx = ensure_numpy(sg.node_idx).astype(np.int64)\n",
    "        x_np = ensure_numpy(sg.x)\n",
    "        for local_i, orig_i in enumerate(node_idx):\n",
    "            feats[orig_i] += x_np[local_i]\n",
    "            feat_count[orig_i] += 1\n",
    "        if hasattr(sg, 'y') and sg.y is not None:\n",
    "            y_np = ensure_numpy(sg.y).reshape(-1)\n",
    "                # 检查标签数量是否与节点数量匹配,\n",
    "            if len(y_np) == len(node_idx):\n",
    "                    # 标签数量与节点数量匹配，正常处理,\n",
    "                    for local_i, orig_i in enumerate(node_idx):\n",
    "                        labels[orig_i] = y_np[local_i]\n",
    "            elif len(y_np) == 1:\n",
    "                    # 只有一个标签，应用到所有节点（图级别标签）\n",
    "                    label_value = y_np[0]\n",
    "                    for orig_i in node_idx:\n",
    "                        labels[orig_i] = label_value\n",
    "            else:\n",
    "                    # 标签数量不匹配，跳过或报警告\n",
    "                    print(f\"警告: 子图标签数量 {len(y_np)} 与节点数量 {len(node_idx)} 不匹配，跳过标签处理\")\n",
    "        # adjacency\n",
    "        adj_local = sg.adj\n",
    "        if isinstance(adj_local, torch.Tensor):\n",
    "            adj_local = adj_local.detach().cpu().numpy()\n",
    "        r_local, c_local = np.nonzero(adj_local)\n",
    "        rows.extend(node_idx[r_local].tolist())\n",
    "        cols.extend(node_idx[c_local].tolist())\n",
    "        data.extend(adj_local[r_local, c_local].tolist())\n",
    "    # average features where multiple assignments\n",
    "    nonzero = feat_count > 0\n",
    "    feats[nonzero] = feats[nonzero] / feat_count[nonzero][:, None]\n",
    "    # build sparse adj\n",
    "    adj_coo = sp.coo_matrix((np.array(data, dtype=np.float64), (np.array(rows), np.array(cols))),\n",
    "                            shape=(num_nodes, num_nodes))\n",
    "    adj_coo.setdiag(0)\n",
    "    adj_coo = adj_coo.tocsr()\n",
    "    adj_coo.eliminate_zeros()\n",
    "    adj_coo = adj_coo.maximum(adj_coo.T)  # 保证对称\n",
    "    # 二值化\n",
    "    adj_bin = (adj_coo > threshold).astype(np.int8)\n",
    "    return adj_bin.tocsr(), feats, labels\n",
    "\n",
    "# helper ensure_numpy\n",
    "def ensure_numpy(x):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x.detach().cpu().numpy()\n",
    "    return np.array(x)\n",
    "\n",
    "# 这里 num_nodes 要设为原始大图节点数（例如 data.x.shape[0]）\n",
    "num_nodes = data.x.shape[0]   # 你在 notebook 最开始加载的 data\n",
    "adj_final, feats_final, labels_final = merge_subgraphs_to_full(modified_graph_list, num_nodes, feature_dim=data.x.shape[1], threshold=0.5)\n",
    "\n",
    "# 保存为 npz（csr components + features + labels）\n",
    "np.savez_compressed('modified_full_graph.npz',\n",
    "                    adj_data=adj_final.data,\n",
    "                    adj_indices=adj_final.indices,\n",
    "                    adj_indptr=adj_final.indptr,\n",
    "                    adj_shape=adj_final.shape,\n",
    "                    features=feats_final.astype(np.float32),\n",
    "                    labels=labels_final.astype(np.int64))\n",
    "print(\"Saved modified_full_graph.npz\")\n",
    "\n",
    "\n",
    "# 同时保存为标准稀疏矩阵格式，兼容 DeepRobust\n",
    "import scipy.sparse as sp\n",
    "sp.save_npz('pubmed_mod_adj_005.npz', adj_final)\n",
    "print(\"Saved pubmed_mod_adj_005.npz (sparse matrix format)\")\n",
    "print(\"Saved pubmed_mod_adj_005.npz (sparse matrix format)\")\n",
    "# 验证保存的文件\n",
    "try:\n",
    "    test_adj = sp.load_npz('pubmed_mod_adj_005.npz')\n",
    "    print(f\"验证成功: pubmed_mod_adj_005.npz - 形状: {test_adj.shape}, 类型: {type(test_adj)}\")\n",
    "except Exception as e:\n",
    "    print(f\"验证失败: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T13:21:06.523533Z",
     "iopub.status.busy": "2025-09-05T13:21:06.523211Z",
     "iopub.status.idle": "2025-09-05T13:21:06.527251Z",
     "shell.execute_reply": "2025-09-05T13:21:06.526636Z",
     "shell.execute_reply.started": "2025-09-05T13:21:06.523506Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#在上述实验中可以发现需要较小的batch_size以支持meta-gradient的计算(e.g., batch_size=16); 如果太大则会出现Out-of-Memory, 因此在这里记录一下梯度图空间复杂度的理论分析：\n",
    "\n",
    "#假设现在有m个子图，平均每个图有n个节点，那么对于一个epoch来说，有m/batch_size个batch;\n",
    "\n",
    "#由于需要拼接整个batch的子图成一个大图，那么这个大图的邻接矩阵规模为 (n * batch_size)^2\n",
    "\n",
    "#综上, 存储的梯度图理论空间复杂度为：\n",
    "#O(m/batch_size*(n*batch_size)^2) = O(m*n^2*batch_size)\n",
    "\n",
    "#进一步考虑到完整的surrogate_training有k个epoch,那么整个surrogate_training的空间复杂度为：\n",
    "#O(k*m*n^2*batch_size)\n",
    "\n",
    "#因此过大的batch_size必然导致过大的内存开销\n",
    "#但如果batch_size过小, 比如极端情况下batch_size=1, 那么理论上讲导致surrogate_training过程过于“琐碎”, 无法感知到训练的全局方向。（TODO, 需要进一步做一个实验）\n",
    "#上面问题更新:目前部分实验做下来batch_size不会特别影响surrogate_training的效果,但batch_size过小将导致更长的开销时间（TODO, 再进一步做一个实验）\n",
    "\n",
    "#现在分析node_injection的理论空间复杂度:\n",
    "#进一步假设注入的节点个数为原图个数的b%,那么一共有m*n*b%个注入节点,每个注入节点只考虑添加到一个子图,因此优化节点注入位置的拓扑有n条,那么需要元梯度的拓扑扰动总数为m*n^2*b%\n",
    "#如果同时也考虑优化节点的d维特征,那么需要元梯度的特征总数为m*n*d*b%\n",
    "#整个surrogate_training的空间复杂度为:\n",
    "#O(k*m*n*(n+d)*b%)\n",
    "\n",
    "#分析O(k*m*n^2*batch_size)和O(k*m*n*(n+d)*b%)大小, 即比较n*batch_size和（n+d）*b%\n",
    "#往往为了不同任务域迁移,需要PCA降维,d不会过大，如100维\n",
    "#因此显然 n*batch_size >>（n+d）*b%\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "GPL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
