{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-05T13:20:34.905828Z",
     "iopub.status.busy": "2025-09-05T13:20:34.905497Z",
     "iopub.status.idle": "2025-09-05T13:20:35.173707Z",
     "shell.execute_reply": "2025-09-05T13:20:35.172902Z",
     "shell.execute_reply.started": "2025-09-05T13:20:34.905802Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting pandas\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/98/af/7be05277859a7bc399da8ba68b88c96b27b48740b6cf49688899c6eb4176/pandas-2.3.3-cp39-cp39-win_amd64.whl (11.4 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/81/c4/34e93fe5f5429d7570ec1fa436f1986fb1f00c3e0f43a589fe2bbcd22c3f/pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/5c/23/c7abc0ca0a1526a0774eca151daeb8de62ec457e77262b66b359c3c7679e/tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "\n",
      "   ---------------------------------------- 0/3 [pytz]\n",
      "   ---------------------------------------- 0/3 [pytz]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   ---------------------------------------- 3/3 [pandas]\n",
      "\n",
      "Successfully installed pandas-2.3.3 pytz-2025.2 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "!pip install pandas numpy \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T13:20:35.175101Z",
     "iopub.status.busy": "2025-09-05T13:20:35.174770Z",
     "iopub.status.idle": "2025-09-05T13:20:40.539853Z",
     "shell.execute_reply": "2025-09-05T13:20:40.538891Z",
     "shell.execute_reply.started": "2025-09-05T13:20:35.175082Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting torch_geometric\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/03/9f/157e913626c1acfb3b19ce000b1a6e4e4fb177c0bc0ea0c67ca5bd714b5a/torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "Collecting aiohttp (from torch_geometric)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ad/a9/d47e7873175a4d8aed425f2cdea2df700b2dd44fac024ffbd83455a69a50/aiohttp-3.13.2-cp39-cp39-win_amd64.whl (456 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch_geometric) (2025.9.0)\n",
      "Collecting jinja2 (from torch_geometric)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/62/a1/3d680cbfd5f4b8f15abc1d571870c5fc3e594bb582bc3b64ea099db13e56/jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch_geometric) (2.0.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch_geometric) (7.0.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch_geometric) (3.2.4)\n",
      "Collecting requests (from torch_geometric)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/1e/db/4254e3eabe8020b458f1a747140d32277ec7a271daf1d235b70dc0b4e6e3/requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Collecting tqdm (from torch_geometric)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp->torch_geometric)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/0f/15/5bf3b99495fb160b63f95972b81750f18f7f4e02ad051373b669d17d44f2/aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp->torch_geometric)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/fb/76/641ae371508676492379f16e2fa48f4e2c11741bd63c48be4b12a6b09cba/aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->torch_geometric)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/fe/ba/e2081de779ca30d473f21f5b30e0e737c438205440784c7dfc81efc2b029/async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->torch_geometric)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/3a/2a/7cc015f5b9f5db42b7d48157e23356022889fc354a2813c15934b7cb5c0e/attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->torch_geometric)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/79/bd/bcc926f87027fad5e59926ff12d136e1082a115025d33c032d1cd69ab377/frozenlist-1.8.0-cp39-cp39-win_amd64.whl (44 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->torch_geometric)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/af/01/547ffe9c2faec91c26965c152f3fea6cff068b6037401f61d310cc861ff4/multidict-6.7.0-cp39-cp39-win_amd64.whl (46 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->torch_geometric)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a4/45/d78d136c3a3d215677abb886785aae744da2c3005bcb99e58640c56529b1/propcache-0.4.1-cp39-cp39-win_amd64.whl (41 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->torch_geometric)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/fd/58/d00f7cad9eba20c4eefac2682f34661d1d1b3a942fc0092eb60e78cfb733/yarl-1.22.0-cp39-cp39-win_amd64.whl (87 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.14.1)\n",
      "Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp->torch_geometric)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/0e/61/66938bbb5fc52dbdf84594873d5b51fb1f7c7794e9c0f5bd885f30bc507b/idna-3.11-py3-none-any.whl (71 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from jinja2->torch_geometric) (3.0.3)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->torch_geometric)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d1/a9/6c040053909d9d1ef4fcab45fddec083aedc9052c10078339b47c8573ea8/charset_normalizer-3.4.4-cp39-cp39-win_amd64.whl (107 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->torch_geometric)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/a7/c2/fe1e52489ae3122415c51f387e221dd0773709bad6c6cdaa599e8a2c5185/urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->torch_geometric)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e4/37/af0d2ef3967ac0d6113837b44a4f0bfe1328c2b9763bd5b1744520e5cfed/certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from tqdm->torch_geometric) (0.4.6)\n",
      "Installing collected packages: urllib3, tqdm, propcache, multidict, jinja2, idna, frozenlist, charset_normalizer, certifi, attrs, async-timeout, aiohappyeyeballs, yarl, requests, aiosignal, aiohttp, torch_geometric\n",
      "\n",
      "   -- -------------------------------------  1/17 [tqdm]\n",
      "   --------- ------------------------------  4/17 [jinja2]\n",
      "   ----------- ----------------------------  5/17 [idna]\n",
      "   --------------------- ------------------  9/17 [attrs]\n",
      "   ------------------------- -------------- 11/17 [aiohappyeyeballs]\n",
      "   ------------------------------ --------- 13/17 [requests]\n",
      "   ----------------------------------- ---- 15/17 [aiohttp]\n",
      "   ----------------------------------- ---- 15/17 [aiohttp]\n",
      "   ------------------------------------- -- 16/17 [torch_geometric]\n",
      "   ------------------------------------- -- 16/17 [torch_geometric]\n",
      "   ------------------------------------- -- 16/17 [torch_geometric]\n",
      "   ------------------------------------- -- 16/17 [torch_geometric]\n",
      "   ------------------------------------- -- 16/17 [torch_geometric]\n",
      "   ------------------------------------- -- 16/17 [torch_geometric]\n",
      "   ------------------------------------- -- 16/17 [torch_geometric]\n",
      "   ------------------------------------- -- 16/17 [torch_geometric]\n",
      "   ------------------------------------- -- 16/17 [torch_geometric]\n",
      "   ------------------------------------- -- 16/17 [torch_geometric]\n",
      "   ------------------------------------- -- 16/17 [torch_geometric]\n",
      "   ------------------------------------- -- 16/17 [torch_geometric]\n",
      "   ------------------------------------- -- 16/17 [torch_geometric]\n",
      "   ---------------------------------------- 17/17 [torch_geometric]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 async-timeout-5.0.1 attrs-25.4.0 certifi-2025.10.5 charset_normalizer-3.4.4 frozenlist-1.8.0 idna-3.11 jinja2-3.1.6 multidict-6.7.0 propcache-0.4.1 requests-2.32.5 torch_geometric-2.6.1 tqdm-4.67.1 urllib3-2.5.0 yarl-1.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T13:20:40.541311Z",
     "iopub.status.busy": "2025-09-05T13:20:40.541009Z",
     "iopub.status.idle": "2025-09-05T13:20:50.529249Z",
     "shell.execute_reply": "2025-09-05T13:20:50.528592Z",
     "shell.execute_reply.started": "2025-09-05T13:20:40.541284Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting torch\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/b9/dc/1f1f621afe15e3c496e1e8f94f8903f75f87e7d642d5a985e92210cc208d/torch-2.8.0-cp39-cp39-win_amd64.whl (241.2 MB)\n",
      "Requirement already satisfied: filelock in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.8.0\n",
      "tensor([[0, 1, 0, 0, 1, 2],\n",
      "        [1, 2, 0, 0, 1, 2]])\n",
      "tensor([[0, 0, 1, 1, 2],\n",
      "        [0, 1, 1, 2, 2]])\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "from torch_geometric.datasets import Planetoid, Amazon, Reddit, WikiCS, Flickr, WebKB, Actor, PolBlogs, CitationFull\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.transforms import AddSelfLoops\n",
    "from torch_geometric.utils import subgraph, k_hop_subgraph\n",
    "import torch_geometric.transforms as T\n",
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch_geometric.nn import global_add_pool, global_max_pool, GlobalAttention, global_mean_pool\n",
    "from torch_geometric.nn.inits import glorot\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 0],\n",
    "                           [1, 2, 0]], dtype=torch.long)\n",
    "x = torch.tensor([[1,2,3],\n",
    "                 [4,5,6],\n",
    "                 [6,7,8]])\n",
    "y = torch.tensor([0,1,2])\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "# 创建 AddSelfLoops 转换\n",
    "add_self_loops = AddSelfLoops()\n",
    "# 应用转换\n",
    "data = add_self_loops(data)\n",
    "print(data.edge_index)\n",
    "data.edge_index = torch.unique(data.edge_index, dim=1)\n",
    "print(data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T13:20:50.531468Z",
     "iopub.status.busy": "2025-09-05T13:20:50.531052Z",
     "iopub.status.idle": "2025-09-05T13:20:50.662444Z",
     "shell.execute_reply": "2025-09-05T13:20:50.661579Z",
     "shell.execute_reply.started": "2025-09-05T13:20:50.531448Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\11326\\\\Desktop\\\\MetaPrompt'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T13:20:50.663825Z",
     "iopub.status.busy": "2025-09-05T13:20:50.663572Z",
     "iopub.status.idle": "2025-09-05T13:21:01.225417Z",
     "shell.execute_reply": "2025-09-05T13:21:01.224580Z",
     "shell.execute_reply.started": "2025-09-05T13:20:50.663803Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting scipy\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/3e/77/dab54fe647a08ee4253963bcd8f9cf17509c8ca64d6335141422fe2e2114/scipy-1.13.1-cp39-cp39-win_amd64.whl (46.2 MB)\n",
      "     ---------------------------------------- 0.0/46.2 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 3.4/46.2 MB 20.2 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 6.0/46.2 MB 15.4 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 8.9/46.2 MB 14.6 MB/s eta 0:00:03\n",
      "     -------- ------------------------------ 10.5/46.2 MB 12.8 MB/s eta 0:00:03\n",
      "     ---------- ---------------------------- 12.1/46.2 MB 13.3 MB/s eta 0:00:03\n",
      "     -------------- ------------------------ 17.3/46.2 MB 13.6 MB/s eta 0:00:03\n",
      "     -------------- ------------------------ 17.6/46.2 MB 13.3 MB/s eta 0:00:03\n",
      "     ----------------- --------------------- 21.2/46.2 MB 12.5 MB/s eta 0:00:02\n",
      "     -------------------- ------------------ 24.1/46.2 MB 12.6 MB/s eta 0:00:02\n",
      "     ----------------------- --------------- 27.5/46.2 MB 12.9 MB/s eta 0:00:02\n",
      "     ------------------------- ------------- 30.1/46.2 MB 12.9 MB/s eta 0:00:02\n",
      "     --------------------------- ----------- 33.0/46.2 MB 12.9 MB/s eta 0:00:02\n",
      "     ----------------------------- --------- 34.9/46.2 MB 12.8 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 36.2/46.2 MB 12.6 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 39.8/46.2 MB 12.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 43.8/46.2 MB 12.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  46.1/46.2 MB 12.9 MB/s eta 0:00:01\n",
      "     --------------------------------------- 46.2/46.2 MB 12.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in c:\\users\\11326\\miniconda3\\envs\\gpl\\lib\\site-packages (from scipy) (2.0.2)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.13.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n",
      "17500\n",
      "18000\n",
      "18500\n",
      "19000\n",
      "19500\n",
      "Data(x=[30, 500], edge_index=[2, 70], y=1, index=0) 0\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy\n",
    "def induced_graphs(data, device, smallest_size=10, largest_size=30):   # 构建诱导图的过程\n",
    "    induced_graph_list = []\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    for index in range(data.x.size(0)):\n",
    "        current_label = data.y[index].item()\n",
    "\n",
    "        current_hop = 2\n",
    "        subset, _, _, _ = k_hop_subgraph(node_idx=index, num_hops=current_hop,\n",
    "                                            edge_index=data.edge_index, relabel_nodes=True)\n",
    "        subset = subset\n",
    "\n",
    "        while len(subset) < smallest_size and current_hop < 5:\n",
    "            current_hop += 1\n",
    "            subset, _, _, _ = k_hop_subgraph(node_idx=index, num_hops=current_hop,\n",
    "                                                edge_index=data.edge_index)\n",
    "            \n",
    "        if len(subset) < smallest_size:\n",
    "            need_node_num = smallest_size - len(subset)\n",
    "            pos_nodes = torch.argwhere(data.y == int(current_label))   # Test data may leak\n",
    "            pos_nodes = pos_nodes.to('cpu')\n",
    "            subset = subset.to('cpu')\n",
    "            candidate_nodes = torch.from_numpy(np.setdiff1d(pos_nodes.numpy(), subset.numpy()))\n",
    "            candidate_nodes = candidate_nodes[torch.randperm(candidate_nodes.shape[0])][0:need_node_num]\n",
    "            subset = torch.cat([torch.flatten(subset), torch.flatten(candidate_nodes)])\n",
    "\n",
    "        if len(subset) > largest_size:\n",
    "            subset = subset[torch.randperm(subset.shape[0])][0:largest_size - 1]\n",
    "            subset = torch.unique(torch.cat([torch.LongTensor([index]).to(device), torch.flatten(subset).to(device)]))\n",
    "\n",
    "        subset = subset.to(device)\n",
    "        sub_edge_index, _ = subgraph(subset, data.edge_index, relabel_nodes=True)\n",
    "        sub_edge_index = sub_edge_index.to(device)\n",
    "\n",
    "        x = data.x[subset]\n",
    "\n",
    "        induced_graph = Data(x=x, edge_index=sub_edge_index, y=data.y[index], index=index, node_idx=subset.cpu())\n",
    "        add_self_loops = AddSelfLoops()\n",
    "        induced_graph = add_self_loops(induced_graph)\n",
    "        induced_graph.edge_index = torch.unique(induced_graph.edge_index, dim=1)\n",
    "        induced_graph_list.append(induced_graph)\n",
    "        if index%500 == 0:\n",
    "            print(index)\n",
    "    return induced_graph_list\n",
    "\n",
    "\n",
    "transform_list = [T.AddSelfLoops(), T.ToUndirected(), T.NormalizeFeatures()]\n",
    "transform = T.Compose(transform_list)\n",
    "dataset = Planetoid(root='c:/Users/11326/Desktop/MetaPrompt', name='PubMed', transform=transform)\n",
    "data = dataset[0]\n",
    "graph_list = induced_graphs(data, 'cpu')\n",
    "print(graph_list[0],graph_list[0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T13:21:01.226791Z",
     "iopub.status.busy": "2025-09-05T13:21:01.226225Z",
     "iopub.status.idle": "2025-09-05T13:21:01.383748Z",
     "shell.execute_reply": "2025-09-05T13:21:01.383108Z",
     "shell.execute_reply.started": "2025-09-05T13:21:01.226758Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[30, 500], edge_index=[2, 70], y=1, index=0, adj=[30, 30])\n"
     ]
    }
   ],
   "source": [
    "def normalize_adj_tensor(adj):\n",
    "    # gcn的归一化邻接矩阵方法\n",
    "    D = torch.sum(adj, dim=1)\n",
    "    D_inv = torch.pow(D, -1 / 2)\n",
    "    D_inv[torch.isinf(D_inv)] = 0.\n",
    "    D_mat_inv = torch.diag(D_inv)\n",
    "    adj_norm = D_mat_inv @ adj @ D_mat_inv  # GCN的归一化方式\n",
    "    return adj_norm\n",
    "\n",
    "def edge_index_to_adjacency_matrix(edge_index, num_nodes, undirected=True, device='cpu'):  \n",
    "    # 将edge_indedx转化为邻接矩阵\n",
    "    # 构建一个大小为 (num_nodes, num_nodes) 的零矩阵  \n",
    "    adjacency_matrix = torch.zeros(num_nodes, num_nodes, dtype=torch.uint8).to(device)\n",
    "      \n",
    "    # 使用索引广播机制，一次性将边索引映射到邻接矩阵的相应位置上  \n",
    "    if undirected:\n",
    "        adjacency_matrix[edge_index[0], edge_index[1]] = 1  \n",
    "        adjacency_matrix[edge_index[1], edge_index[0]] = 1  \n",
    "    else:\n",
    "        adjacency_matrix[edge_index[0], edge_index[1]] = 1\n",
    "    return adjacency_matrix\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "size_buffer = []\n",
    "for graph in graph_list:\n",
    "    size_buffer.append(graph.x.shape[0])\n",
    "    adj = edge_index_to_adjacency_matrix(graph.edge_index, graph.x.shape[0])\n",
    "    graph.adj = adj\n",
    "\n",
    "print(graph_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T13:21:01.384837Z",
     "iopub.status.busy": "2025-09-05T13:21:01.384534Z",
     "iopub.status.idle": "2025-09-05T13:21:01.394604Z",
     "shell.execute_reply": "2025-09-05T13:21:01.393841Z",
     "shell.execute_reply.started": "2025-09-05T13:21:01.384809Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, graph_list):\n",
    "        self.graph_list = graph_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graph_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graph_list[idx]\n",
    "\n",
    "class SequentialGraphLoader(DataLoader):\n",
    "    def __init__(self, graph_list, batch_size=1):\n",
    "        dataset = GraphDataset(graph_list)\n",
    "        super(SequentialGraphLoader, self).__init__(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.dataset), self.batch_size):\n",
    "            batch = self.dataset[i:i+self.batch_size]\n",
    "            yield self.merge_graphs(batch)\n",
    "\n",
    "    def merge_graphs(self, batch):\n",
    "        # 合并子图的特征矩阵和邻接矩阵\n",
    "        x_buffer = []\n",
    "        adj_list = []\n",
    "        y_buffer = []\n",
    "        batch_sizes = []\n",
    "        batch_indexs = []\n",
    "        graph_indexs = []\n",
    "\n",
    "        for i, graph in enumerate(batch):\n",
    "            x = graph.x\n",
    "            adj = graph.adj\n",
    "            y = graph.y.unsqueeze(0)  # 确保 y 是二维张量\n",
    "            x_buffer.append(x)\n",
    "            adj_list.append(adj)\n",
    "            y_buffer.append(y)\n",
    "            batch_sizes.append(x.shape[0])  # 存储子图的大小\n",
    "            batch_indexs = batch_indexs + [i] * x.shape[0]\n",
    "            graph_indexs.append(graph.index)\n",
    "\n",
    "        # 将特征矩阵堆叠\n",
    "        x_combined = torch.cat(x_buffer, dim=0)  # 合并特征矩阵\n",
    "        num_nodes = x_combined.size(0)  # 所有节点的总数\n",
    "        \n",
    "        # 构建大的邻接矩阵\n",
    "        adj_combined = torch.zeros(num_nodes, num_nodes, device=x_combined.device)\n",
    "        start = 0\n",
    "        for i in range(len(batch)):\n",
    "            end = start + batch_sizes[i]\n",
    "            adj_combined[start:end, start:end] = adj_list[i]  # 填充对应的子图邻接矩阵\n",
    "            start = end\n",
    "\n",
    "        y_combined = torch.cat(y_buffer, dim=0)  # 合并标签\n",
    "        batch_indexs = torch.tensor(batch_indexs)\n",
    "\n",
    "        return x_combined, adj_combined, y_combined, batch_sizes, batch_indexs, graph_indexs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T13:21:01.396107Z",
     "iopub.status.busy": "2025-09-05T13:21:01.395431Z",
     "iopub.status.idle": "2025-09-05T13:21:06.522402Z",
     "shell.execute_reply": "2025-09-05T13:21:06.521691Z",
     "shell.execute_reply.started": "2025-09-05T13:21:01.396078Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_num: 0\n",
      "epoch_num: 1\n",
      "epoch_num: 2\n",
      "epoch_num: 3\n",
      "epoch_num: 4\n",
      "epoch_num: 5\n",
      "epoch_num: 6\n",
      "epoch_num: 7\n",
      "epoch_num: 8\n",
      "epoch_num: 9\n",
      "done\n",
      "tensor([[ 0.0000,  0.1303,  0.1988, -0.0009, -0.2279,  0.0238,  0.3515,  0.1057,\n",
      "          0.0676, -0.1496,  0.2897,  0.1671,  0.2784,  0.5615,  0.1402, -0.0403,\n",
      "          0.3323, -0.0269,  0.1713, -0.0370, -0.0536,  0.0782, -0.3244,  0.1684,\n",
      "          0.1267, -0.0102, -0.1639, -0.1298,  0.4705],\n",
      "        [-0.1303,  0.0000,  0.0686, -0.1312, -0.3582, -0.1065,  0.2213, -0.0245,\n",
      "         -0.0626, -0.2799,  0.1594,  0.0368,  0.1481,  0.4313,  0.0099, -0.1706,\n",
      "          0.2021, -0.1572,  0.0410, -0.1673, -0.1839, -0.0520, -0.4547,  0.0381,\n",
      "         -0.0036, -0.1405, -0.2941, -0.2601,  0.3403],\n",
      "        [-0.1988, -0.0686,  0.0000, -0.1998, -0.4268, -0.1751,  0.1527, -0.0931,\n",
      "         -0.1312, -0.3485,  0.0909, -0.0317,  0.0795,  0.3627, -0.0587, -0.2392,\n",
      "          0.1335, -0.2258, -0.0276, -0.2359, -0.2525, -0.1206, -0.5233, -0.0305,\n",
      "         -0.0721, -0.2090, -0.3627, -0.3287,  0.2717],\n",
      "        [ 0.0009,  0.1312,  0.1998,  0.0000, -0.2270,  0.0247,  0.3525,  0.1066,\n",
      "          0.0686, -0.1487,  0.2906,  0.1680,  0.2793,  0.5625,  0.1411, -0.0394,\n",
      "          0.3333, -0.0260,  0.1722, -0.0361, -0.0527,  0.0792, -0.3235,  0.1693,\n",
      "          0.1276, -0.0093, -0.1630, -0.1289,  0.4715],\n",
      "        [ 0.2279,  0.3582,  0.4268,  0.2270,  0.0000,  0.2517,  0.5795,  0.3337,\n",
      "          0.2956,  0.0783,  0.5177,  0.3950,  0.5063,  0.7895,  0.3681,  0.1876,\n",
      "          0.5603,  0.2010,  0.3992,  0.1909,  0.1743,  0.3062, -0.0965,  0.3963,\n",
      "          0.3547,  0.2178,  0.0641,  0.0981,  0.6985],\n",
      "        [-0.0238,  0.1065,  0.1751, -0.0247, -0.2517,  0.0000,  0.3278,  0.0820,\n",
      "          0.0439, -0.1734,  0.2659,  0.1433,  0.2546,  0.5378,  0.1164, -0.0641,\n",
      "          0.3086, -0.0507,  0.1475, -0.0608, -0.0774,  0.0545, -0.3482,  0.1446,\n",
      "          0.1029, -0.0340, -0.1876, -0.1536,  0.4468],\n",
      "        [-0.2337, -0.1483, -0.1034, -0.2343, -0.3830, -0.2181,  0.0000, -0.1644,\n",
      "         -0.1893, -0.3317, -0.0438, -0.1242, -0.0489,  0.1343, -0.1418, -0.2601,\n",
      "         -0.0200, -0.2513, -0.1214, -0.2579, -0.2688, -0.1824, -0.4463, -0.1233,\n",
      "         -0.1457, -0.2403, -0.3411, -0.3187,  0.0747],\n",
      "        [-0.1057,  0.0245,  0.0931, -0.1066, -0.3337, -0.0820,  0.2458,  0.0000,\n",
      "         -0.0381, -0.2554,  0.1840,  0.0614,  0.1726,  0.4558,  0.0345, -0.1460,\n",
      "          0.2266, -0.1327,  0.0655, -0.1428, -0.1593, -0.0275, -0.4301,  0.0627,\n",
      "          0.0210, -0.1159, -0.2696, -0.2355,  0.3648],\n",
      "        [-0.0676,  0.0626,  0.1312, -0.0686, -0.2956, -0.0439,  0.2839,  0.0381,\n",
      "          0.0000, -0.2173,  0.2221,  0.0995,  0.2107,  0.4939,  0.0725, -0.1080,\n",
      "          0.2647, -0.0946,  0.1036, -0.1047, -0.1212,  0.0106, -0.3921,  0.1007,\n",
      "          0.0591, -0.0778, -0.2315, -0.1975,  0.4029],\n",
      "        [ 0.1496,  0.2799,  0.3485,  0.1487, -0.0783,  0.1734,  0.5012,  0.2554,\n",
      "          0.2173,  0.0000,  0.4394,  0.3167,  0.4280,  0.7112,  0.2898,  0.1093,\n",
      "          0.4820,  0.1227,  0.3209,  0.1126,  0.0960,  0.2279, -0.1748,  0.3180,\n",
      "          0.2764,  0.1394, -0.0142,  0.0198,  0.6202],\n",
      "        [-0.2897, -0.1594, -0.0909, -0.2906, -0.5177, -0.2659,  0.0618, -0.1840,\n",
      "         -0.2221, -0.4394,  0.0000, -0.1226, -0.0113,  0.2718, -0.1495, -0.3300,\n",
      "          0.0426, -0.3167, -0.1185, -0.3268, -0.3433, -0.2115, -0.6141, -0.1213,\n",
      "         -0.1630, -0.2999, -0.4536, -0.4195,  0.1808],\n",
      "        [-0.1671, -0.0368,  0.0317, -0.1680, -0.3950, -0.1433,  0.1844, -0.0614,\n",
      "         -0.0995, -0.3167,  0.1226,  0.0000,  0.1113,  0.3944, -0.0269, -0.2074,\n",
      "          0.1652, -0.1940,  0.0042, -0.2041, -0.2207, -0.0888, -0.4915,  0.0013,\n",
      "         -0.0404, -0.1773, -0.3310, -0.2969,  0.3034],\n",
      "        [-0.1993, -0.1139, -0.0690, -0.1999, -0.3487, -0.1837,  0.0321, -0.1300,\n",
      "         -0.1550, -0.2973, -0.0094, -0.0898,  0.0000,  0.1687, -0.1074, -0.2257,\n",
      "          0.0144, -0.2169, -0.0871, -0.2236, -0.2344, -0.1480, -0.4119, -0.0889,\n",
      "         -0.1113, -0.2060, -0.3067, -0.2844,  0.1091],\n",
      "        [-0.5615, -0.4313, -0.3627, -0.5625, -0.7895, -0.5378, -0.2100, -0.4558,\n",
      "         -0.4939, -0.7112, -0.2718, -0.3944, -0.2832,  0.0000, -0.4214, -0.6019,\n",
      "         -0.2292, -0.5885, -0.3903, -0.5986, -0.6151, -0.4833, -0.8859, -0.3931,\n",
      "         -0.4348, -0.5717, -0.7254, -0.6914, -0.0910],\n",
      "        [-0.1402, -0.0099,  0.0587, -0.1411, -0.3681, -0.1164,  0.2114, -0.0345,\n",
      "         -0.0725, -0.2898,  0.1495,  0.0269,  0.1382,  0.4214,  0.0000, -0.1805,\n",
      "          0.1922, -0.1671,  0.0311, -0.1772, -0.1938, -0.0619, -0.4646,  0.0282,\n",
      "         -0.0135, -0.1504, -0.3041, -0.2700,  0.3303],\n",
      "        [ 0.0403,  0.1706,  0.2392,  0.0394, -0.1876,  0.0641,  0.3919,  0.1460,\n",
      "          0.1080, -0.1093,  0.3300,  0.2074,  0.3187,  0.6019,  0.1805,  0.0000,\n",
      "          0.3727,  0.0134,  0.2116,  0.0033, -0.0133,  0.1186, -0.2841,  0.2087,\n",
      "          0.1670,  0.0301, -0.1236, -0.0895,  0.5109],\n",
      "        [-0.1615, -0.0862, -0.0466, -0.1620, -0.2932, -0.1478,  0.0400, -0.1004,\n",
      "         -0.1224, -0.2479,  0.0059, -0.0650, -0.0042,  0.1629, -0.0805, -0.1848,\n",
      "          0.0000, -0.1771, -0.0626, -0.1829, -0.1925, -0.1163, -0.3489, -0.0642,\n",
      "         -0.0957, -0.1674, -0.2562, -0.2365,  0.1103],\n",
      "        [ 0.0269,  0.1572,  0.2258,  0.0260, -0.2010,  0.0507,  0.3785,  0.1327,\n",
      "          0.0946, -0.1227,  0.3167,  0.1940,  0.3053,  0.5885,  0.1671, -0.0134,\n",
      "          0.3593,  0.0000,  0.1982, -0.0101, -0.0267,  0.1052, -0.2975,  0.1953,\n",
      "          0.1537,  0.0168, -0.1369, -0.1029,  0.4975],\n",
      "        [-0.1713, -0.0410,  0.0276, -0.1722, -0.3992, -0.1475,  0.1803, -0.0655,\n",
      "         -0.1036, -0.3209,  0.1185, -0.0042,  0.1071,  0.3903, -0.0311, -0.2116,\n",
      "          0.1611, -0.1982,  0.0000, -0.2083, -0.2249, -0.0930, -0.4957, -0.0029,\n",
      "         -0.0445, -0.1815, -0.3351, -0.3011,  0.2993],\n",
      "        [ 0.0370,  0.1673,  0.2359,  0.0361, -0.1909,  0.0608,  0.3886,  0.1428,\n",
      "          0.1047, -0.1126,  0.3268,  0.2041,  0.3154,  0.5986,  0.1772, -0.0033,\n",
      "          0.3694,  0.0101,  0.2083,  0.0000, -0.0166,  0.1153, -0.2874,  0.2054,\n",
      "          0.1638,  0.0268, -0.1268, -0.0928,  0.5076],\n",
      "        [ 0.0536,  0.1839,  0.2525,  0.0527, -0.1743,  0.0774,  0.4051,  0.1593,\n",
      "          0.1212, -0.0960,  0.3433,  0.2207,  0.3320,  0.6151,  0.1938,  0.0133,\n",
      "          0.3859,  0.0267,  0.2249,  0.0166,  0.0000,  0.1319, -0.2708,  0.2220,\n",
      "          0.1803,  0.0434, -0.1103, -0.0762,  0.5241],\n",
      "        [-0.0782,  0.0520,  0.1206, -0.0792, -0.3062, -0.0545,  0.2733,  0.0275,\n",
      "         -0.0106, -0.2279,  0.2115,  0.0888,  0.2001,  0.4833,  0.0619, -0.1186,\n",
      "          0.2541, -0.1052,  0.0930, -0.1153, -0.1319,  0.0000, -0.4027,  0.0901,\n",
      "          0.0485, -0.0884, -0.2421, -0.2081,  0.3923],\n",
      "        [ 0.3244,  0.4547,  0.5233,  0.3235,  0.0965,  0.3482,  0.6759,  0.4301,\n",
      "          0.3921,  0.1748,  0.6141,  0.4915,  0.6028,  0.8859,  0.4646,  0.2841,\n",
      "          0.6567,  0.2975,  0.4957,  0.2874,  0.2708,  0.4027,  0.0000,  0.4928,\n",
      "          0.4511,  0.3142,  0.1605,  0.1946,  0.7949],\n",
      "        [-0.1684, -0.0381,  0.0305, -0.1693, -0.3963, -0.1446,  0.1832, -0.0627,\n",
      "         -0.1007, -0.3180,  0.1213, -0.0013,  0.1100,  0.3931, -0.0282, -0.2087,\n",
      "          0.1640, -0.1953,  0.0029, -0.2054, -0.2220, -0.0901, -0.4928,  0.0000,\n",
      "         -0.0417, -0.1786, -0.3323, -0.2982,  0.3021],\n",
      "        [-0.1280, -0.0426,  0.0023, -0.1286, -0.2774, -0.1124,  0.1034, -0.0587,\n",
      "         -0.0837, -0.2261,  0.0618, -0.0185,  0.0567,  0.2400, -0.0361, -0.1544,\n",
      "          0.0856, -0.1457, -0.0158, -0.1523, -0.1631, -0.0767, -0.3406, -0.0177,\n",
      "          0.0000, -0.1347, -0.2354, -0.2131,  0.1803],\n",
      "        [ 0.0102,  0.1405,  0.2090,  0.0093, -0.2178,  0.0340,  0.3617,  0.1159,\n",
      "          0.0778, -0.1394,  0.2999,  0.1773,  0.2886,  0.5717,  0.1504, -0.0301,\n",
      "          0.3425, -0.0168,  0.1815, -0.0268, -0.0434,  0.0884, -0.3142,  0.1786,\n",
      "          0.1369,  0.0000, -0.1537, -0.1196,  0.4807],\n",
      "        [ 0.1639,  0.2941,  0.3627,  0.1630, -0.0641,  0.1876,  0.5154,  0.2696,\n",
      "          0.2315,  0.0142,  0.4536,  0.3310,  0.4422,  0.7254,  0.3041,  0.1236,\n",
      "          0.4962,  0.1369,  0.3351,  0.1268,  0.1103,  0.2421, -0.1605,  0.3323,\n",
      "          0.2906,  0.1537,  0.0000,  0.0341,  0.6344],\n",
      "        [ 0.1298,  0.2601,  0.3287,  0.1289, -0.0981,  0.1536,  0.4814,  0.2355,\n",
      "          0.1975, -0.0198,  0.4195,  0.2969,  0.4082,  0.6914,  0.2700,  0.0895,\n",
      "          0.4622,  0.1029,  0.3011,  0.0928,  0.0762,  0.2081, -0.1946,  0.2982,\n",
      "          0.2565,  0.1196, -0.0341,  0.0000,  0.6003],\n",
      "        [-0.4705, -0.3403, -0.2717, -0.4715, -0.6985, -0.4468, -0.1190, -0.3648,\n",
      "         -0.4029, -0.6202, -0.1808, -0.3034, -0.1922,  0.0910, -0.3303, -0.5109,\n",
      "         -0.1382, -0.4975, -0.2993, -0.5076, -0.5241, -0.3923, -0.7949, -0.3021,\n",
      "         -0.3438, -0.4807, -0.6344, -0.6003,  0.0000]])\n",
      "Saved modified_full_graph.npz\n",
      "Saved pubmed_mod_adj_005.npz (sparse matrix format)\n",
      "Saved pubmed_mod_adj_005.npz (sparse matrix format)\n",
      "验证成功: pubmed_mod_adj_005.npz - 形状: (19717, 19717), 类型: <class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Batch, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import math\n",
    "import copy\n",
    "\n",
    "modified_graph_list = copy.deepcopy(graph_list)\n",
    "adj_changes = [torch.nn.Parameter(torch.FloatTensor(size, size)) for size in size_buffer] # 对每个子图的扰动\n",
    "for adj_change in adj_changes:\n",
    "    adj_change.data.fill_(0)\n",
    "for modified_graph, graph, adj_change in zip(modified_graph_list, graph_list, adj_changes):\n",
    "    change_square = adj_change - torch.diag(torch.diag(adj_change, 0))\n",
    "    change_square = torch.clamp(change_square, -1, 1)\n",
    "    modified_graph.adj = change_square + graph.adj\n",
    "\n",
    "train_loader = SequentialGraphLoader(modified_graph_list[:800], batch_size=16) # 定义的Dataloader\n",
    "test_loader = SequentialGraphLoader(modified_graph_list[800:], batch_size=16)\n",
    "weights = []\n",
    "w_velocities = []\n",
    "hidden_sizes = [128 for i in range(2)]\n",
    "previous_size = 500\n",
    "out_dim = 7\n",
    "for ix, nhid in enumerate(hidden_sizes):\n",
    "    weight = torch.nn.Parameter(torch.FloatTensor(previous_size, nhid).to(device))\n",
    "    w_velocity = torch.zeros(weight.shape).to(device)\n",
    "    weights.append(weight)\n",
    "    w_velocities.append(w_velocity)\n",
    "    previous_size = nhid\n",
    "    \n",
    "output_weight = torch.nn.Parameter(torch.FloatTensor(previous_size, out_dim).to(device))\n",
    "output_w_velocity = torch.zeros(output_weight.shape).to(device)\n",
    "weights.append(output_weight)\n",
    "w_velocities.append(output_w_velocity)\n",
    "for w, v in zip(weights, w_velocities):\n",
    "    stdv = 1. / math.sqrt(w.size(1))\n",
    "    w.data.uniform_(-stdv, stdv)\n",
    "    v.data.fill_(0)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # 分类任务的损失函数\n",
    "\n",
    "\n",
    "#初始化参数,避免梯度爆炸\n",
    "for w, v in zip(weights, w_velocities):\n",
    "    stdv = 1. / math.sqrt(w.size(1))\n",
    "    w.data.uniform_(-stdv, stdv)\n",
    "    v.data.fill_(0)\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(\"epoch_num:\", epoch)\n",
    "    for x, adj, y, sizes, batch_indexs, graph_indexs in train_loader:\n",
    "        loss = 0.0\n",
    "        x, adj, y, batch_indexs = x.to(device), adj.to(device), y.to(device), batch_indexs.to(device)\n",
    "        adj_norm = normalize_adj_tensor(adj)\n",
    "        \n",
    "        # 图卷积\n",
    "        for i, w in enumerate(weights):\n",
    "            if i != len(weights)-1:\n",
    "                x = adj_norm @ x @ w\n",
    "            else:\n",
    "                x = global_mean_pool(x, batch_indexs) @ w\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = criterion(x, y)\n",
    "        assert torch.isnan(loss).any()==False, \"loss is NaN\"\n",
    "        if torch.isnan(loss).any():\n",
    "            raise ValueError(\"loss is NaN!\")\n",
    "        weight_grads = torch.autograd.grad(loss, weights, create_graph=True)\n",
    "        w_velocities = [0.9 * v + g for v, g in zip(w_velocities, weight_grads)]\n",
    "        weights = [w - 0.01 * v for w, v in zip(weights, w_velocities)]\n",
    "        \n",
    "total_loss = 0.0\n",
    "for x, adj, y, sizes, batch_indexs, graph_indexs in test_loader:\n",
    "    x, adj, y, batch_indexs = x.to(device), adj.to(device), y.to(device), batch_indexs.to(device)\n",
    "    adj_norm = normalize_adj_tensor(adj)\n",
    "    \n",
    "    # 图卷积\n",
    "    for i, w in enumerate(weights):\n",
    "        if i != len(weights)-1:\n",
    "            x = adj_norm @ x @ w\n",
    "        else:\n",
    "            x = global_mean_pool(x, batch_indexs) @ w\n",
    "        \n",
    "    # 累计损失\n",
    "    total_loss += criterion(x, y) * x.shape[0]\n",
    "\n",
    "total_loss.backward(retain_graph=False)\n",
    "\n",
    "# 提取元梯度\n",
    "adj_grads = [adj_change.grad for adj_change in adj_changes]\n",
    "\n",
    "# 验证形状\n",
    "for grad, adj_change in zip(adj_grads, adj_changes):\n",
    "    assert grad.shape == adj_change.shape\n",
    "print(\"done\")\n",
    "print(adj_grads[0])\n",
    "# -------------------------\n",
    "# 在 total_loss.backward(...) 和 adj_grads 之后运行\n",
    "# -------------------------\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# attack_ratio: 你在 adj_changes 定义处设定，比如 0.05 表示每个子图翻 / 注入 5% 的“可能边位”\n",
    "# 若你还没定义，请在这里设置（或改为从上面单元读取）\n",
    "attack_ratio = 0.50\n",
    "\n",
    "# adj_grads 已经存在（list of tensors，shape 与对应 adj_change 相同）\n",
    "# graph_list 与 modified_graph_list 在前面单元已定义\n",
    "adj_grads = [g.detach().cpu().numpy() for g in adj_grads]  # 转 numpy 便于处理\n",
    "\n",
    "def apply_budgeted_flips_to_subgraph(orig_adj, grad_mat, ratio):\n",
    "    \"\"\"\n",
    "    orig_adj: torch tensor 或 numpy 二值邻接 (n_i, n_i)\n",
    "    grad_mat: numpy ndarray, 对应 adj_change.grad 的绝对值敏感度矩阵 (n_i, n_i)\n",
    "    ratio: 比例 (0~1)，表示要翻转的边/位置占上三角（不含对角）的比例\n",
    "    返回: 修改后的二值邻接 numpy (n_i, n_i)\n",
    "    \"\"\"\n",
    "    if isinstance(orig_adj, torch.Tensor):\n",
    "        A = orig_adj.detach().cpu().numpy().astype(np.int8)\n",
    "    else:\n",
    "        A = np.array(orig_adj, dtype=np.int8)\n",
    "    n = A.shape[0]\n",
    "    # 只考虑上三角（i<j）的候选位置（无向图）\n",
    "    iu = np.triu_indices(n, k=1)\n",
    "    # score = abs(grad)\n",
    "    scores = np.abs(grad_mat[iu])\n",
    "    m = len(scores)\n",
    "    k = max(1, int(np.round(ratio * m)))  # 至少选 1 个\n",
    "    if k >= m:\n",
    "        top_idx = np.arange(m)\n",
    "    else:\n",
    "        top_idx = np.argpartition(-scores, k-1)[:k]  # top-k indices within iu\n",
    "    rows = iu[0][top_idx]\n",
    "    cols = iu[1][top_idx]\n",
    "    # flip edges at (rows, cols)\n",
    "    A_new = A.copy()\n",
    "    A_new[rows, cols] = 1 - A_new[rows, cols]  # flip: 1->0, 0->1\n",
    "    A_new[cols, rows] = A_new[rows, cols]      # 对称\n",
    "    # 保持对角为0\n",
    "    np.fill_diagonal(A_new, 0)\n",
    "    return A_new\n",
    "\n",
    "# 遍历每个子图，按比例把梯度大的位置翻转成最终的二值邻接\n",
    "for i, (sg, grad) in enumerate(zip(modified_graph_list, adj_grads)):\n",
    "    # sg.adj 可能是 torch.Tensor；把 grad 传进去\n",
    "    new_adj = apply_budgeted_flips_to_subgraph(sg.adj, grad, attack_ratio)\n",
    "    # 把 numpy 转回 torch（或保持 numpy，后面拼接时统一处理）\n",
    "    sg.adj = torch.from_numpy(new_adj).to(sg.x.device)\n",
    "\n",
    "# 至此 modified_graph_list 已经包含“最终二值化后的子图邻接”\n",
    "# 下一步：把子图拼回为一张大图并保存为 npz\n",
    "# 需要每个 subgraph 包含原图 node id 映射：graph.index（你的 induced_graph 保存了 index 字段）\n",
    "# 如果每个 subgraph 里有 attribute 'index' 为中心节点 id，可以用它和子图节点顺序做映射（若你在构造子图时保留了 node_idx 那更好）\n",
    "\n",
    "# 这里基于你的 induced_graphs 函数：每个 subgraph 的 .index = 中心节点（单个node）\n",
    "# 如果想要正确拼回原大图（non-overlapping partition），你必须在构造子图时保存 node_idx（原始节点 ids）。\n",
    "# 假设你已经把 node_idx 存在每个 subgraph（名称为 'node_idx'），否则需要在划分时保存。\n",
    "\n",
    "# 我这里实现一个 merge（非重叠子图或平均策略），先根据 node_idx 填 features 和 edges\n",
    "def merge_subgraphs_to_full(modified_graph_list, num_nodes, feature_dim=None, threshold=0.5):\n",
    "    # features\n",
    "    # assume every sg.x shape = (n_i, d) and sg.node_idx exists\n",
    "    d = feature_dim if feature_dim is not None else ensure_numpy(modified_graph_list[0].x).shape[1]\n",
    "    feats = np.zeros((num_nodes, d), dtype=np.float32)\n",
    "    feat_count = np.zeros((num_nodes,), dtype=np.int32)\n",
    "    rows = []\n",
    "    cols = []\n",
    "    data = []\n",
    "    labels = np.full((num_nodes,), -1, dtype=np.int64)\n",
    "    for sg in modified_graph_list:\n",
    "        if not hasattr(sg, 'node_idx'):\n",
    "            raise RuntimeError(\"每个子图必须包含 node_idx 用于拼回原图。请在 induced_graphs 时保存 node_idx。\")\n",
    "        node_idx = ensure_numpy(sg.node_idx).astype(np.int64)\n",
    "        x_np = ensure_numpy(sg.x)\n",
    "        for local_i, orig_i in enumerate(node_idx):\n",
    "            feats[orig_i] += x_np[local_i]\n",
    "            feat_count[orig_i] += 1\n",
    "        if hasattr(sg, 'y') and sg.y is not None:\n",
    "            y_np = ensure_numpy(sg.y).reshape(-1)\n",
    "                # 检查标签数量是否与节点数量匹配,\n",
    "            if len(y_np) == len(node_idx):\n",
    "                    # 标签数量与节点数量匹配，正常处理,\n",
    "                    for local_i, orig_i in enumerate(node_idx):\n",
    "                        labels[orig_i] = y_np[local_i]\n",
    "            elif len(y_np) == 1:\n",
    "                    # 只有一个标签，应用到所有节点（图级别标签）\n",
    "                    label_value = y_np[0]\n",
    "                    for orig_i in node_idx:\n",
    "                        labels[orig_i] = label_value\n",
    "            else:\n",
    "                    # 标签数量不匹配，跳过或报警告\n",
    "                    print(f\"警告: 子图标签数量 {len(y_np)} 与节点数量 {len(node_idx)} 不匹配，跳过标签处理\")\n",
    "        # adjacency\n",
    "        adj_local = sg.adj\n",
    "        if isinstance(adj_local, torch.Tensor):\n",
    "            adj_local = adj_local.detach().cpu().numpy()\n",
    "        r_local, c_local = np.nonzero(adj_local)\n",
    "        rows.extend(node_idx[r_local].tolist())\n",
    "        cols.extend(node_idx[c_local].tolist())\n",
    "        data.extend(adj_local[r_local, c_local].tolist())\n",
    "    # average features where multiple assignments\n",
    "    nonzero = feat_count > 0\n",
    "    feats[nonzero] = feats[nonzero] / feat_count[nonzero][:, None]\n",
    "    # build sparse adj\n",
    "    adj_coo = sp.coo_matrix((np.array(data, dtype=np.float64), (np.array(rows), np.array(cols))),\n",
    "                            shape=(num_nodes, num_nodes))\n",
    "    adj_coo.setdiag(0)\n",
    "    adj_coo = adj_coo.tocsr()\n",
    "    adj_coo.eliminate_zeros()\n",
    "    adj_coo = adj_coo.maximum(adj_coo.T)  # 保证对称\n",
    "    # 二值化\n",
    "    adj_bin = (adj_coo > threshold).astype(np.int8)\n",
    "    return adj_bin.tocsr(), feats, labels\n",
    "\n",
    "# helper ensure_numpy\n",
    "def ensure_numpy(x):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x.detach().cpu().numpy()\n",
    "    return np.array(x)\n",
    "\n",
    "# 这里 num_nodes 要设为原始大图节点数（例如 data.x.shape[0]）\n",
    "num_nodes = data.x.shape[0]   # 你在 notebook 最开始加载的 data\n",
    "adj_final, feats_final, labels_final = merge_subgraphs_to_full(modified_graph_list, num_nodes, feature_dim=data.x.shape[1], threshold=0.5)\n",
    "\n",
    "# 保存为 npz（csr components + features + labels）\n",
    "np.savez_compressed('modified_full_graph.npz',\n",
    "                    adj_data=adj_final.data,\n",
    "                    adj_indices=adj_final.indices,\n",
    "                    adj_indptr=adj_final.indptr,\n",
    "                    adj_shape=adj_final.shape,\n",
    "                    features=feats_final.astype(np.float32),\n",
    "                    labels=labels_final.astype(np.int64))\n",
    "print(\"Saved modified_full_graph.npz\")\n",
    "\n",
    "\n",
    "# 同时保存为标准稀疏矩阵格式，兼容 DeepRobust\n",
    "import scipy.sparse as sp\n",
    "sp.save_npz('pubmed_mod_adj_005.npz', adj_final)\n",
    "print(\"Saved pubmed_mod_adj_005.npz (sparse matrix format)\")\n",
    "print(\"Saved pubmed_mod_adj_005.npz (sparse matrix format)\")\n",
    "# 验证保存的文件\n",
    "try:\n",
    "    test_adj = sp.load_npz('pubmed_mod_adj_005.npz')\n",
    "    print(f\"验证成功: pubmed_mod_adj_005.npz - 形状: {test_adj.shape}, 类型: {type(test_adj)}\")\n",
    "except Exception as e:\n",
    "    print(f\"验证失败: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T13:21:06.523533Z",
     "iopub.status.busy": "2025-09-05T13:21:06.523211Z",
     "iopub.status.idle": "2025-09-05T13:21:06.527251Z",
     "shell.execute_reply": "2025-09-05T13:21:06.526636Z",
     "shell.execute_reply.started": "2025-09-05T13:21:06.523506Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#在上述实验中可以发现需要较小的batch_size以支持meta-gradient的计算(e.g., batch_size=16); 如果太大则会出现Out-of-Memory, 因此在这里记录一下梯度图空间复杂度的理论分析：\n",
    "\n",
    "#假设现在有m个子图，平均每个图有n个节点，那么对于一个epoch来说，有m/batch_size个batch;\n",
    "\n",
    "#由于需要拼接整个batch的子图成一个大图，那么这个大图的邻接矩阵规模为 (n * batch_size)^2\n",
    "\n",
    "#综上, 存储的梯度图理论空间复杂度为：\n",
    "#O(m/batch_size*(n*batch_size)^2) = O(m*n^2*batch_size)\n",
    "\n",
    "#进一步考虑到完整的surrogate_training有k个epoch,那么整个surrogate_training的空间复杂度为：\n",
    "#O(k*m*n^2*batch_size)\n",
    "\n",
    "#因此过大的batch_size必然导致过大的内存开销\n",
    "#但如果batch_size过小, 比如极端情况下batch_size=1, 那么理论上讲导致surrogate_training过程过于“琐碎”, 无法感知到训练的全局方向。（TODO, 需要进一步做一个实验）\n",
    "#上面问题更新:目前部分实验做下来batch_size不会特别影响surrogate_training的效果,但batch_size过小将导致更长的开销时间（TODO, 再进一步做一个实验）\n",
    "\n",
    "#现在分析node_injection的理论空间复杂度:\n",
    "#进一步假设注入的节点个数为原图个数的b%,那么一共有m*n*b%个注入节点,每个注入节点只考虑添加到一个子图,因此优化节点注入位置的拓扑有n条,那么需要元梯度的拓扑扰动总数为m*n^2*b%\n",
    "#如果同时也考虑优化节点的d维特征,那么需要元梯度的特征总数为m*n*d*b%\n",
    "#整个surrogate_training的空间复杂度为:\n",
    "#O(k*m*n*(n+d)*b%)\n",
    "\n",
    "#分析O(k*m*n^2*batch_size)和O(k*m*n*(n+d)*b%)大小, 即比较n*batch_size和（n+d）*b%\n",
    "#往往为了不同任务域迁移,需要PCA降维,d不会过大，如100维\n",
    "#因此显然 n*batch_size >>（n+d）*b%\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "GPL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
