#!/usr/bin/env python3
"""
æµ‹è¯•Mettackæ•°æ®é›†ä¸EdgeFlipMAEæ¨¡å‹é›†æˆçš„å¯è¡Œæ€§
"""

import os
import sys
import numpy as np
import torch
import json
from pathlib import Path

# æ·»åŠ è·¯å¾„ä»¥å¯¼å…¥ç›¸å…³æ¨¡å—
sys.path.append(str(Path(__file__).parent))
sys.path.append(str(Path(__file__).parent.parent / "DeepRobust" / "examples" / "graph"))

try:
    from mettack_to_edgeflip_integration import (
        load_mettack_dataset,
        extract_node_features_from_pairs,
        create_graph_from_pairs,
        train_edgeflip_mae_with_mettack_data
    )
    from EdgeFlipMAE import EdgeFlipMAE
    print("âœ… æˆåŠŸå¯¼å…¥æ‰€æœ‰å¿…éœ€æ¨¡å—")
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    sys.exit(1)


def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½åŠŸèƒ½"""
    print("\n=== æµ‹è¯•1: æ•°æ®åŠ è½½åŠŸèƒ½ ===")
    
    # æŸ¥æ‰¾å¯ç”¨çš„æ•°æ®æ–‡ä»¶
    data_dir = Path(__file__).parent.parent / "DeepRobust" / "examples" / "graph"
    npz_files = list(data_dir.glob("*edgeflip_dataset*.npz"))
    
    if not npz_files:
        print("âŒ æœªæ‰¾åˆ°mettackç”Ÿæˆçš„æ•°æ®æ–‡ä»¶")
        print("è¯·å…ˆè¿è¡Œ test_mettack.py ç”Ÿæˆæ•°æ®é›†")
        return False, None
    
    npz_path = npz_files[0]
    print(f"ğŸ“ æ‰¾åˆ°æ•°æ®æ–‡ä»¶: {npz_path.name}")
    
    try:
        # æµ‹è¯•æ•°æ®åŠ è½½
        dataset_dict = load_mettack_dataset(str(npz_path))
        
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ")
        print(f"   - æ ·æœ¬æ•°é‡: {len(dataset_dict['y'])}")
        print(f"   - ç‰¹å¾ç»´åº¦: {dataset_dict['X_pairs'].shape[1]}")
        print(f"   - æ­£æ ·æœ¬æ¯”ä¾‹: {np.mean(dataset_dict['y']):.4f}")
        print(f"   - èŠ‚ç‚¹å¯¹æ•°é‡: {len(dataset_dict['pairs'])}")
        
        return True, dataset_dict
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return False, None


def test_feature_extraction(dataset_dict):
    """æµ‹è¯•ç‰¹å¾æå–åŠŸèƒ½"""
    print("\n=== æµ‹è¯•2: ç‰¹å¾æå–åŠŸèƒ½ ===")
    
    try:
        X_pairs = dataset_dict['X_pairs']
        pairs = dataset_dict['pairs']
        
        # æ¨æ–­èŠ‚ç‚¹æ•°é‡ - ä¿®å¤ç´¢å¼•é—®é¢˜
        n_nodes = int(pairs.max()) + 1  # ä½¿ç”¨max()+1
        
        print(f"ğŸ“Š æ¨æ–­èŠ‚ç‚¹æ•°é‡: {n_nodes}")
        
        # æå–èŠ‚ç‚¹ç‰¹å¾
        node_features = extract_node_features_from_pairs(X_pairs, pairs, n_nodes)
        
        print(f"âœ… ç‰¹å¾æå–æˆåŠŸ")
        print(f"   - èŠ‚ç‚¹ç‰¹å¾å½¢çŠ¶: {node_features.shape}")
        print(f"   - ç‰¹å¾èŒƒå›´: [{node_features.min():.4f}, {node_features.max():.4f}]")
        print(f"   - ç‰¹å¾å‡å€¼: {node_features.mean():.4f}")
        
        return True, node_features
        
    except Exception as e:
        print(f"âŒ ç‰¹å¾æå–å¤±è´¥: {e}")
        return False, None


def test_graph_creation(pairs, node_features):
    """æµ‹è¯•å›¾åˆ›å»ºåŠŸèƒ½"""
    print("\n=== æµ‹è¯•3: å›¾åˆ›å»ºåŠŸèƒ½ ===")
    
    try:
        # åˆ›å»ºå›¾æ•°æ®
        graph_data = create_graph_from_pairs(pairs, node_features)
        
        print(f"âœ… å›¾åˆ›å»ºæˆåŠŸ")
        print(f"   - èŠ‚ç‚¹æ•°é‡: {graph_data.num_nodes}")
        print(f"   - è¾¹æ•°é‡: {graph_data.num_edges}")
        print(f"   - èŠ‚ç‚¹ç‰¹å¾ç»´åº¦: {graph_data.x.shape[1]}")
        print(f"   - å›¾è¿é€šæ€§: {graph_data.num_edges / (2 * graph_data.num_nodes):.2f}")
        
        return True, graph_data
        
    except Exception as e:
        print(f"âŒ å›¾åˆ›å»ºå¤±è´¥: {e}")
        return False, None


def test_model_initialization(node_feat_dim):
    """æµ‹è¯•æ¨¡å‹åˆå§‹åŒ–"""
    print("\n=== æµ‹è¯•4: æ¨¡å‹åˆå§‹åŒ– ===")
    
    try:
        # åˆå§‹åŒ–EdgeFlipMAEæ¨¡å‹
        model = EdgeFlipMAE(
            gnn_type='GCN',
            input_dim=node_feat_dim,
            hid_dim=32,  # ä½¿ç”¨è¾ƒå°çš„ç»´åº¦è¿›è¡Œæµ‹è¯•
            num_layer=2,
            mask_rate=0.15,
            noise_rate=0.1
        )
        
        print(f"âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
        print(f"   - æ¨¡å‹ç±»å‹: {model.gnn_type}")
        print(f"   - è¾“å…¥ç»´åº¦: {model.input_dim}")
        print(f"   - éšè—ç»´åº¦: {model.hid_dim}")
        print(f"   - å±‚æ•°: {model.num_layer}")
        
        return True, model
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
        return False, None


def test_data_loading_into_model(model, dataset_dict, graph_data):
    """æµ‹è¯•æ•°æ®åŠ è½½åˆ°æ¨¡å‹"""
    print("\n=== æµ‹è¯•5: æ•°æ®åŠ è½½åˆ°æ¨¡å‹ ===")
    
    try:
        # å‡†å¤‡æ•°æ®
        edge_pairs = dataset_dict['pairs']
        X_pairs = dataset_dict['X_pairs']
        labels = dataset_dict['y']
        
        print(f"ğŸ“Š å‡†å¤‡åŠ è½½æ•°æ®åˆ°æ¨¡å‹...")
        print(f"   - è¾¹å¯¹æ•°é‡: {len(edge_pairs)}")
        print(f"   - æ ‡ç­¾æ•°é‡: {len(labels)}")
        
        # åŠ è½½æ•°æ®åˆ°æ¨¡å‹
        model.load_triplet_data(
            edge_pairs=edge_pairs,
            X_pairs=X_pairs,
            labels=labels,
            graph_data=graph_data,
            train_ratio=0.6,
            val_ratio=0.2
        )
        
        print("âœ… æ•°æ®åŠ è½½åˆ°æ¨¡å‹æˆåŠŸ")
        print(f"   - è®­ç»ƒé›†å¤§å°: {len(model.train_dataset)}")
        print(f"   - éªŒè¯é›†å¤§å°: {len(model.val_dataset)}")
        print(f"   - æµ‹è¯•é›†å¤§å°: {len(model.test_dataset)}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½åˆ°æ¨¡å‹å¤±è´¥: {e}")
        return False


def test_short_training(model):
    """æµ‹è¯•çŸ­æ—¶é—´è®­ç»ƒ"""
    print("\n=== æµ‹è¯•6: çŸ­æ—¶é—´è®­ç»ƒ ===")
    
    try:
        print("ğŸš€ å¼€å§‹çŸ­æ—¶é—´è®­ç»ƒæµ‹è¯• (2ä¸ªepoch)...")
        
        # ä¸´æ—¶ä¿®æ”¹epochsè¿›è¡ŒçŸ­æ—¶é—´è®­ç»ƒ
        original_epochs = model.epochs
        model.epochs = 50
        
        # è¿›è¡ŒçŸ­æ—¶é—´è®­ç»ƒ
        model.pretrain(batch_size=32)  # ä½¿ç”¨è¾ƒå°çš„batch size
        
        # æ¢å¤åŸå§‹epochs
        model.epochs = original_epochs
        
        print("âœ… çŸ­æ—¶é—´è®­ç»ƒæˆåŠŸå®Œæˆ")
        
        # æµ‹è¯•è¯„ä¼°
        print("ğŸ“Š æµ‹è¯•æ¨¡å‹è¯„ä¼°...")
        from torch.utils.data import DataLoader
        test_loader = DataLoader(model.test_dataset, batch_size=32, shuffle=False)
        metrics = model.evaluate(test_loader)
        
        print("âœ… æ¨¡å‹è¯„ä¼°æˆåŠŸ")
        print(f"   - å‡†ç¡®ç‡: {metrics.get('accuracy', 'N/A'):.4f}")
        print(f"   - F1åˆ†æ•°: {metrics.get('f1', 'N/A'):.4f}")
        print(f"   - AUC: {metrics.get('auc', 'N/A'):.4f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def run_comprehensive_test():
    """è¿è¡Œç»¼åˆæµ‹è¯•"""
    print("ğŸ” å¼€å§‹Mettack-EdgeFlipMAEé›†æˆå¯è¡Œæ€§æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•1: æ•°æ®åŠ è½½
    success, dataset_dict = test_data_loading()
    if not success:
        return False
    
    # æµ‹è¯•2: ç‰¹å¾æå–
    success, node_features = test_feature_extraction(dataset_dict)
    if not success:
        return False
    
    # æµ‹è¯•3: å›¾åˆ›å»º
    success, graph_data = test_graph_creation(dataset_dict['pairs'], node_features)
    if not success:
        return False
    
    # æµ‹è¯•4: æ¨¡å‹åˆå§‹åŒ–
    success, model = test_model_initialization(node_features.shape[1])
    if not success:
        return False
    
    # æµ‹è¯•5: æ•°æ®åŠ è½½åˆ°æ¨¡å‹
    success = test_data_loading_into_model(model, dataset_dict, graph_data)
    if not success:
        return False
    
    # æµ‹è¯•6: çŸ­æ—¶é—´è®­ç»ƒ
    success = test_short_training(model)
    if not success:
        return False
    
    return True


def generate_test_report():
    """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ")
    
    report = {
        "test_time": str(np.datetime64('now')),
        "test_status": "PASSED" if run_comprehensive_test() else "FAILED",
        "environment": {
            "python_version": sys.version,
            "torch_version": torch.__version__,
            "numpy_version": np.__version__
        }
    }
    
    # ä¿å­˜æµ‹è¯•æŠ¥å‘Š
    report_path = Path(__file__).parent / "integration_test_report.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“„ æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
    
    return report["test_status"] == "PASSED"


if __name__ == "__main__":
    print("ğŸ§ª Mettack-EdgeFlipMAEé›†æˆæµ‹è¯•")
    print("=" * 60)
    
    try:
        success = generate_test_report()
        
        if success:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼é›†æˆæ–¹æ¡ˆå¯è¡Œæ€§éªŒè¯æˆåŠŸï¼")
            print("\nğŸ“š æ¥ä¸‹æ¥æ‚¨å¯ä»¥ï¼š")
            print("   1. æŸ¥çœ‹ usage_guide.md äº†è§£è¯¦ç»†ä½¿ç”¨æ–¹æ³•")
            print("   2. è¿è¡Œ mettack_to_edgeflip_integration.py è¿›è¡Œå®Œæ•´è®­ç»ƒ")
            print("   3. æ ¹æ®éœ€è¦è°ƒæ•´æ¨¡å‹è¶…å‚æ•°")
        else:
            print("\nâŒ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤é—®é¢˜")
            
    except KeyboardInterrupt:
        print("\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()